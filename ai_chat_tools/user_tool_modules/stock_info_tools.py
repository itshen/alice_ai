# MODULE_DESCRIPTION: å…¨é¢çš„è¯åˆ¸äº¤æ˜“å¸‚åœºä¿¡æ¯å·¥å…·é›†åˆï¼Œæä¾›è‚¡ç¥¨åŸºæœ¬é¢åˆ†æã€æŠ€æœ¯åˆ†æã€å®æ—¶èµ„è®¯å’Œå¸‚åœºæ’è¡Œæ¦œç­‰åŠŸèƒ½
# MODULE_CATEGORY: stock_info
# MODULE_AUTHOR: Luoxiaoshan
# MODULE_VERSION: 2.0.0

"""
è¯åˆ¸äº¤æ˜“å¸‚åœºä¿¡æ¯å·¥å…·æ¨¡å—
æä¾›å®Œæ•´çš„é‡‘èå¸‚åœºæ•°æ®è·å–å’Œåˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

ğŸ“Š åŸºæœ¬é¢åˆ†æï¼š
- è·å–å…¬å¸æ¦‚å†µä¿¡æ¯ï¼ˆç¾è‚¡ã€æ¸¯è‚¡ã€Aè‚¡ï¼‰
- è·å–è´¢åŠ¡æŒ‡æ ‡æ•°æ®ï¼ˆç›ˆåˆ©èƒ½åŠ›ã€æˆé•¿æ€§ã€å¿å€ºèƒ½åŠ›ã€è¥è¿èƒ½åŠ›ç­‰ï¼‰
- è·å–åˆ©æ¶¦è¡¨æ•°æ®ï¼ˆè¥ä¸šæ”¶å…¥ã€æˆæœ¬ã€å‡€åˆ©æ¶¦ç­‰æŸç›Šé¡¹ç›®ï¼‰
- è·å–èµ„äº§è´Ÿå€ºè¡¨æ•°æ®ï¼ˆèµ„äº§ã€è´Ÿå€ºã€è‚¡ä¸œæƒç›Šç­‰è´¢åŠ¡çŠ¶å†µï¼‰

ğŸ“ˆ æŠ€æœ¯åˆ†æï¼š
- è·å–å®æ—¶è‚¡ä»·å’ŒKçº¿æ•°æ®
- è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆMACDã€KDJã€å¸ƒæ—å¸¦ã€SARã€ç§»åŠ¨å¹³å‡çº¿ç­‰ï¼‰
- æä¾›ä¸“ä¸šçš„æŠ€æœ¯åˆ†ææ‘˜è¦å’ŒæŠ•èµ„å»ºè®®

ğŸ“° å¸‚åœºèµ„è®¯ï¼š
- è·å–è‚¡ç¥¨ç›¸å…³æ–°é—»èµ„è®¯ï¼Œæ”¯æŒå¹¶å‘è·å–å®Œæ•´å†…å®¹
- æ™ºèƒ½å…³é”®è¯æœç´¢å’Œä¸­è‹±æ–‡è‚¡ç¥¨åç§°è½¬æ¢
- æä¾›ä¸°å¯Œçš„å¸‚åœºä¿¡æ¯ç”¨äºæŠ•èµ„å†³ç­–

ğŸ“Š å¸‚åœºæ’è¡Œæ¦œï¼š
- å®æ—¶æ¶¨å¹…æ¦œã€è·Œå¹…æ¦œã€æˆäº¤é‡æ¦œã€æˆäº¤é¢æ¦œ
- æ”¯æŒç¾è‚¡ã€æ¸¯è‚¡ã€Aè‚¡ä¸‰å¤§å¸‚åœº
- ç”¨äºå¸‚åœºçƒ­ç‚¹åˆ†æå’ŒæŠ•èµ„æœºä¼šå‘ç°

ğŸ”§ å·¥å…·ç‰¹æ€§ï¼š
- æ”¯æŒæ‰¹é‡æŸ¥è¯¢å’Œè‡ªåŠ¨å¸‚åœºç±»å‹æ£€æµ‹
- æ™ºèƒ½è‚¡ç¥¨ä»£ç æ ¼å¼è¯†åˆ«å’Œæ ‡å‡†åŒ–
- ä¸“ä¸šçš„æ•°æ®åˆ†æå’Œå¯è§†åŒ–è¾“å‡º
- ä¸“é—¨ç”¨äºAIé‡åŒ–äº¤æ˜“å’ŒæŠ•èµ„åˆ†æ
"""

import os
import json
import re
import time
from typing import Dict, Any, Optional, List, Union
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

# ä½¿ç”¨ç»å¯¹å¯¼å…¥é¿å…ç›¸å¯¹å¯¼å…¥é—®é¢˜
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from ai_chat_tools.tool_manager import register_tool
from ai_chat_tools.config import config

# å¯¼å…¥webæŠ“å–å·¥å…·çš„ç®¡ç†å™¨
try:
    from ai_chat_tools.user_tool_modules.web_scraping_tools import _web_scraper, WebScraperManager
    WEB_SCRAPER_AVAILABLE = True
except ImportError:
    WEB_SCRAPER_AVAILABLE = False
    _web_scraper = None
    WebScraperManager = None

# ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================

class MarketType(Enum):
    """å¸‚åœºç±»å‹æšä¸¾"""
    US = "us"           # ç¾è‚¡
    HK = "hk"           # æ¸¯è‚¡
    CN = "cn"           # Aè‚¡
    UK = "uk"           # è‹±è‚¡
    JP = "jp"           # æ—¥è‚¡

@dataclass
class CompanyInfo:
    """å…¬å¸åŸºæœ¬ä¿¡æ¯"""
    symbol: str                         # è‚¡ç¥¨ä»£ç 
    org_name_cn: Optional[str] = None   # ä¸­æ–‡å…¬å¸åç§°
    org_name_en: Optional[str] = None   # è‹±æ–‡å…¬å¸åç§°
    org_short_name_cn: Optional[str] = None  # ä¸­æ–‡ç®€ç§°
    org_short_name_en: Optional[str] = None  # è‹±æ–‡ç®€ç§°
    main_operation_business: Optional[str] = None  # ä¸»è¥ä¸šåŠ¡
    org_introduction: Optional[str] = None  # å…¬å¸ä»‹ç»
    established_date: Optional[str] = None  # æˆç«‹æ—¥æœŸ
    listed_date: Optional[str] = None       # ä¸Šå¸‚æ—¥æœŸ
    staff_num: Optional[int] = None         # å‘˜å·¥æ•°é‡
    website: Optional[str] = None           # å…¬å¸ç½‘ç«™
    chairman: Optional[str] = None          # è‘£äº‹é•¿
    market_type: Optional[str] = None       # å¸‚åœºç±»å‹
    trading_market: Optional[str] = None    # äº¤æ˜“æ‰€

# ==================== è‚¡ç¥¨ä¿¡æ¯ç®¡ç†å™¨ ====================

class StockInfoManager:
    """è‚¡ç¥¨ä¿¡æ¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.base_urls = {
            MarketType.US: "https://stock.xueqiu.com/v5/stock/f10/us/company.json",
            MarketType.HK: "https://stock.xueqiu.com/v5/stock/f10/hk/company.json", 
            MarketType.CN: "https://stock.xueqiu.com/v5/stock/f10/cn/company.json"
        }
        
        # è´¢åŠ¡æŒ‡æ ‡API URLs
        self.finance_urls = {
            MarketType.US: "https://stock.xueqiu.com/v5/stock/finance/us/indicator.json",
            MarketType.HK: "https://stock.xueqiu.com/v5/stock/finance/hk/indicator.json",
            MarketType.CN: "https://stock.xueqiu.com/v5/stock/finance/cn/indicator.json"
        }
        
        # åˆ©æ¶¦è¡¨API URLs  
        self.income_urls = {
            MarketType.US: "https://stock.xueqiu.com/v5/stock/finance/us/income.json",
            MarketType.HK: "https://stock.xueqiu.com/v5/stock/finance/hk/income.json",
            MarketType.CN: "https://stock.xueqiu.com/v5/stock/finance/cn/income.json"
        }
        
        # é›ªçƒAPIéœ€è¦çš„è¯·æ±‚å¤´
        self.xueqiu_headers = {
            'accept': 'application/json, text/plain, */*',
            'accept-language': 'zh-CN,zh;q=0.9,ko;q=0.8,en-US;q=0.7,en;q=0.6',
            'cache-control': 'no-cache',
            'origin': 'https://xueqiu.com',
            'referer': 'https://xueqiu.com/',
            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
            'cookie': 's=be12bcx3pb; cookiesu=971748192631827; device_id=afda57cfe6697001d99fa8895d7a8922; u=971748192631827; Hm_lvt_1db88642e346389874251b5a1eded6e3=1748192633,1749565221; HMACCOUNT=73EFE7072B2EF8EE; xq_a_token=b7259d09435458cc3f1a963479abb270a1a016ce; xqat=b7259d09435458cc3f1a963479abb270a1a016ce; xq_r_token=28108bfa1d92ac8a46bbb57722633746218621a3; xq_id_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ1aWQiOi0xLCJpc3MiOiJ1YyIsImV4cCI6MTc1MjU0MTk4OCwiY3RtIjoxNzQ5OTk0MzEyODE0LCJjaWQiOiJkOWQwbjRBWnVwIn0.jNWjZYg_wpiX1GgMAlx7hE9ZE8pTjQg6V5NgsM7O2vSbzM_yE4np01eywM_aKem3L0sh3bMqgbpZT8IG0L61oJ7yEV84aO6wajvfSgP8NOtkNJxDk6ljYG57-fgau9Ig1Vpi49_Md-fM4BXQeza0sgHXnBLnvv7LyVks5Z1puo4mr_pGIyKYr_o5MtWRFGNZBRpDtTQ0SgYn8pQWJ9ceu9EojXvYeelq4hny4Gocgj6yvnaInlyimJA3own6mb5d0a067ypFnZ9YP3UG_jcBndeXn5OX1wNmeBcHgGTwH_vN33bo6vjb1Nqhu7v2Hb4WpLrjyK8POAFUjivQ7THdkA; Hm_lpvt_1db88642e346389874251b5a1eded6e3=1749994377; ssxmod_itna=YqUxnDcDBC0QiQ=i7NitYiOqDQK4ijKQDXDUqMq7tDRDFqApxDH8mrF5stfB=8YKnDG=45aY5D/zG7eDZDG9dDqx0ErXQA7Tthe9G7gqpPfl0Y4hkW80GSYaYQI=RxYifUzSc65c7eGImDG2DYoDCqDS0DD9R2GrDYYfDBYD74G+DDeDixbDGuuP2DDFRWbdclNQiW+PueDE000a0DDgjPD1QPWrulNqla4D0LWDfR0WleqxxY=DQwOQFoTDjR9W7KGyQeGWi8RjuKGuSZixphuNqPqU=RDSzCLxW7eM+BxPfA6hznGxngxNAD4EsPYs3AxYA4qY5=nQkxDic5Kb2rBqK4U2atq1UriXYAm=e52YI6DKrUxr/Dgpw1nwKAG5mDIA03iiGGDK3X3YD; ssxmod_itna2=YqUxnDcDBC0QiQ=i7NitYiOqDQK4ijKQDXDUqMq7tDRDFqApxDH8mrF5stfB=8YKnDG=45a7eDAQf7G+C=fQD03qe8G3TPDBMpP4WMYZ5y53fY=RcKkBFEhWq3m+7DHhYA+sYgERHupq29iQ4YMLxWw6Hebfu80DRAbQh+CiujLr2fkrnKe4DpCXx5W5eWj3lSf+Xzeh4wO0HQG2K8Gj5m8rZ7MhW=TQkrYc5K0rk57fPvfhSzTF8yQcKnL4Qwg6EgbUU7Zxipai6Kpi2uZxNLUdu2UiCM8g4T/C=cR18=7m5covxo0sEYGiCmxnrZ0pV/bDNuqzir9GE+bZKGEQRY9GPLAtQDNfGNW0qbD40BPsiKPD'
        }
        
        # åˆ›å»ºæ•°æ®å­˜å‚¨ç›®å½•
        self.data_dir = os.path.join(os.getcwd(), "stock_data")
        os.makedirs(self.data_dir, exist_ok=True)
    
    def _detect_market_type(self, symbol: str) -> MarketType:
        """æ ¹æ®è‚¡ç¥¨ä»£ç è‡ªåŠ¨æ£€æµ‹å¸‚åœºç±»å‹"""
        symbol = symbol.upper().strip()
        
        # Aè‚¡åˆ¤æ–­
        if symbol.startswith(('SH', 'SZ')):
            return MarketType.CN
        if re.match(r'^[036]\d{5}$', symbol):  # 6ä½æ•°å­—ï¼Œ0/3/6å¼€å¤´
            return MarketType.CN
            
        # æ¸¯è‚¡åˆ¤æ–­
        if re.match(r'^0\d{4}$', symbol):  # 5ä½æ•°å­—ï¼Œ0å¼€å¤´
            return MarketType.HK
        if symbol.startswith('HK'):
            return MarketType.HK
            
        # ç¾è‚¡åˆ¤æ–­ï¼ˆé»˜è®¤ï¼‰
        return MarketType.US
    
    def _normalize_symbol(self, symbol: str, market_type: MarketType) -> str:
        """æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç æ ¼å¼"""
        symbol = symbol.upper().strip()
        
        if market_type == MarketType.CN:
            # Aè‚¡ä»£ç å¤„ç†
            if symbol.startswith(('SH', 'SZ')):
                return symbol
            elif symbol.startswith('6'):
                return f'SH{symbol}'
            elif symbol.startswith(('0', '3')):
                return f'SZ{symbol}'
        elif market_type == MarketType.HK:
            # æ¸¯è‚¡ä»£ç å¤„ç†
            if symbol.startswith('HK'):
                symbol = symbol[2:]
            if len(symbol) < 5:
                symbol = symbol.zfill(5)
        
        return symbol
    
    def _format_timestamp(self, timestamp: Optional[Union[int, float]]) -> Optional[str]:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºæ—¥æœŸå­—ç¬¦ä¸²"""
        if timestamp is None:
            return None
        try:
            # å¤„ç†æ¯«ç§’æ—¶é—´æˆ³
            if timestamp > 1e10:
                timestamp = timestamp / 1000
            return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
        except:
            return None
    
    def _extract_company_info(self, data: Dict[str, Any], symbol: str, market_type: MarketType) -> CompanyInfo:
        """ä»APIå“åº”ä¸­æå–å…¬å¸ä¿¡æ¯"""
        company_data = data.get('data', {}).get('company', {})
        
        return CompanyInfo(
            symbol=symbol,
            org_name_cn=company_data.get('org_name_cn'),
            org_name_en=company_data.get('org_name_en'),
            org_short_name_cn=company_data.get('org_short_name_cn'),
            org_short_name_en=company_data.get('org_short_name_en'),
            main_operation_business=company_data.get('main_operation_business'),
            org_introduction=company_data.get('org_cn_introduction') or company_data.get('org_en_introduction'),
            established_date=self._format_timestamp(company_data.get('established_date')),
            listed_date=self._format_timestamp(company_data.get('listed_date')),
            staff_num=company_data.get('staff_num'),
            website=company_data.get('org_website'),
            chairman=company_data.get('chairman'),
            market_type=market_type.value,
            trading_market=company_data.get('td_mkt')
        )
    
    def get_company_overview(self, symbol: str, market_type: Optional[str] = None, 
                           save_data: bool = False) -> Dict[str, Any]:
        """è·å–å…¬å¸æ¦‚å†µä¿¡æ¯"""
        if not WEB_SCRAPER_AVAILABLE:
            return {
                'success': False,
                'error': 'WebæŠ“å–å·¥å…·ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿web_scraping_toolsæ¨¡å—æ­£å¸¸å¯¼å…¥'
            }
        
        try:
            # ç¡®å®šå¸‚åœºç±»å‹
            if market_type:
                try:
                    market_enum = MarketType(market_type.lower())
                except ValueError:
                    market_enum = self._detect_market_type(symbol)
            else:
                market_enum = self._detect_market_type(symbol)
            
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
            normalized_symbol = self._normalize_symbol(symbol, market_enum)
            
            # æ„å»ºAPI URL
            if market_enum not in self.base_urls:
                return {
                    'success': False,
                    'error': f'æš‚ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market_enum.value}'
                }
            
            api_url = f"{self.base_urls[market_enum]}?symbol={normalized_symbol}"
            
            # è®¾ç½®referer
            headers = self.xueqiu_headers.copy()
            headers['referer'] = f'https://xueqiu.com/snowman/S/{normalized_symbol}/detail'
            
            # ä½¿ç”¨web_scraperå‘é€APIè¯·æ±‚
            if _web_scraper is None:
                return {
                    'success': False,
                    'error': 'WebæŠ“å–å·¥å…·å®ä¾‹ä¸å¯ç”¨'
                }
            
            result = _web_scraper.api_request(
                url=api_url,
                method="GET",
                headers=headers,
                timeout=30
            )
            
            if not result['success']:
                return {
                    'success': False,
                    'error': f'APIè¯·æ±‚å¤±è´¥: {result["error"]}'
                }
            
            if not result['is_json']:
                return {
                    'success': False,
                    'error': 'å“åº”ä¸æ˜¯JSONæ ¼å¼'
                }
            
            # æ£€æŸ¥APIå“åº”çŠ¶æ€
            api_data = result['json']
            if api_data.get('error_code', 0) != 0:
                return {
                    'success': False,
                    'error': f'APIè¿”å›é”™è¯¯: {api_data.get("error_description", "æœªçŸ¥é”™è¯¯")}'
                }
            
            # æå–å…¬å¸ä¿¡æ¯
            company_info = self._extract_company_info(api_data, normalized_symbol, market_enum)
            
            # ä¿å­˜æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            filepath = None
            if save_data:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"company_overview_{normalized_symbol}_{timestamp}.json"
                filepath = os.path.join(self.data_dir, filename)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(api_data, f, ensure_ascii=False, indent=2)
            
            return {
                'success': True,
                'data': {
                    'company_info': company_info,
                    'raw_data': api_data,
                    'api_url': api_url,
                    'market_type': market_enum.value,
                    'normalized_symbol': normalized_symbol
                },
                'filepath': filepath
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è·å–å…¬å¸æ¦‚å†µå¤±è´¥: {str(e)}'
            }
    
    def get_financial_indicators(self, symbol: str, market_type: Optional[str] = None, 
                               count: int = 5, save_data: bool = False) -> Dict[str, Any]:
        """è·å–è´¢åŠ¡æŒ‡æ ‡æ•°æ®"""
        if not WEB_SCRAPER_AVAILABLE:
            return {
                'success': False,
                'error': 'WebæŠ“å–å·¥å…·ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿web_scraping_toolsæ¨¡å—æ­£å¸¸å¯¼å…¥'
            }
        
        try:
            # ç¡®å®šå¸‚åœºç±»å‹
            if market_type:
                try:
                    market_enum = MarketType(market_type.lower())
                except ValueError:
                    market_enum = self._detect_market_type(symbol)
            else:
                market_enum = self._detect_market_type(symbol)
            
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
            normalized_symbol = self._normalize_symbol(symbol, market_enum)
            
            # æ„å»ºAPI URL
            if market_enum not in self.finance_urls:
                return {
                    'success': False,
                    'error': f'æš‚ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market_enum.value}'
                }
            
            # æ„å»ºè´¢åŠ¡æŒ‡æ ‡APIå‚æ•°
            import time
            timestamp = int(time.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
            
            params = {
                'symbol': normalized_symbol,
                'type': 'all',
                'is_detail': 'true',
                'count': str(count),
                'timestamp': str(timestamp)
            }
            
            api_url = self.finance_urls[market_enum]
            
            # è®¾ç½®referer
            headers = self.xueqiu_headers.copy()
            headers['referer'] = f'https://xueqiu.com/snowman/S/{normalized_symbol}/detail'
            
            # ä½¿ç”¨web_scraperå‘é€APIè¯·æ±‚
            if _web_scraper is None:
                return {
                    'success': False,
                    'error': 'WebæŠ“å–å·¥å…·å®ä¾‹ä¸å¯ç”¨'
                }
            
            result = _web_scraper.api_request(
                url=api_url,
                method="GET",
                headers=headers,
                data=params,
                timeout=30
            )
            
            if not result['success']:
                return {
                    'success': False,
                    'error': f'APIè¯·æ±‚å¤±è´¥: {result["error"]}'
                }
            
            if not result['is_json']:
                return {
                    'success': False,
                    'error': 'å“åº”ä¸æ˜¯JSONæ ¼å¼'
                }
            
            # æ£€æŸ¥APIå“åº”çŠ¶æ€
            api_data = result['json']
            if api_data.get('error_code', 0) != 0:
                return {
                    'success': False,
                    'error': f'APIè¿”å›é”™è¯¯: {api_data.get("error_description", "æœªçŸ¥é”™è¯¯")}'
                }
            
            # ä¿å­˜æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            filepath = None
            if save_data:
                timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"financial_indicators_{normalized_symbol}_{timestamp_str}.json"
                filepath = os.path.join(self.data_dir, filename)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(api_data, f, ensure_ascii=False, indent=2)
            
            return {
                'success': True,
                'data': {
                    'raw_data': api_data,
                    'api_url': f"{api_url}?{result['url'].split('?')[1] if '?' in result['url'] else ''}",
                    'market_type': market_enum.value,
                    'normalized_symbol': normalized_symbol
                },
                'filepath': filepath
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è·å–è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {str(e)}'
            }
    
    def get_income_statement(self, symbol: str, market_type: Optional[str] = None, 
                           count: int = 5, save_data: bool = False) -> Dict[str, Any]:
        """è·å–åˆ©æ¶¦è¡¨æ•°æ®"""
        if not WEB_SCRAPER_AVAILABLE:
            return {
                'success': False,
                'error': 'WebæŠ“å–å·¥å…·ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿web_scraping_toolsæ¨¡å—æ­£å¸¸å¯¼å…¥'
            }
        
        try:
            # ç¡®å®šå¸‚åœºç±»å‹
            if market_type:
                try:
                    market_enum = MarketType(market_type.lower())
                except ValueError:
                    market_enum = self._detect_market_type(symbol)
            else:
                market_enum = self._detect_market_type(symbol)
            
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
            normalized_symbol = self._normalize_symbol(symbol, market_enum)
            
            # æ„å»ºAPI URL
            if market_enum not in self.income_urls:
                return {
                    'success': False,
                    'error': f'æš‚ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market_enum.value}'
                }
            
            # æ„å»ºåˆ©æ¶¦è¡¨APIå‚æ•°
            import time
            timestamp = int(time.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
            
            params = {
                'symbol': normalized_symbol,
                'type': 'all',
                'is_detail': 'true',
                'count': str(count),
                'timestamp': str(timestamp)
            }
            
            api_url = self.income_urls[market_enum]
            
            # è®¾ç½®referer
            headers = self.xueqiu_headers.copy()
            headers['referer'] = f'https://xueqiu.com/snowman/S/{normalized_symbol}/detail'
            
            # ä½¿ç”¨web_scraperå‘é€APIè¯·æ±‚
            if _web_scraper is None:
                return {
                    'success': False,
                    'error': 'WebæŠ“å–å·¥å…·å®ä¾‹ä¸å¯ç”¨'
                }
            
            result = _web_scraper.api_request(
                url=api_url,
                method="GET",
                headers=headers,
                data=params,
                timeout=30
            )
            
            if not result['success']:
                return {
                    'success': False,
                    'error': f'APIè¯·æ±‚å¤±è´¥: {result["error"]}'
                }
            
            if not result['is_json']:
                return {
                    'success': False,
                    'error': 'å“åº”ä¸æ˜¯JSONæ ¼å¼'
                }
            
            # æ£€æŸ¥APIå“åº”çŠ¶æ€
            api_data = result['json']
            if api_data.get('error_code', 0) != 0:
                return {
                    'success': False,
                    'error': f'APIè¿”å›é”™è¯¯: {api_data.get("error_description", "æœªçŸ¥é”™è¯¯")}'
                }
            
            # ä¿å­˜æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            filepath = None
            if save_data:
                timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"income_statement_{normalized_symbol}_{timestamp_str}.json"
                filepath = os.path.join(self.data_dir, filename)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(api_data, f, ensure_ascii=False, indent=2)
            
            return {
                'success': True,
                'data': {
                    'raw_data': api_data,
                    'api_url': f"{api_url}?{result['url'].split('?')[1] if '?' in result['url'] else ''}",
                    'market_type': market_enum.value,
                    'normalized_symbol': normalized_symbol
                },
                'filepath': filepath
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è·å–åˆ©æ¶¦è¡¨å¤±è´¥: {str(e)}'
            }

# åˆ›å»ºå…¨å±€å®ä¾‹
_stock_manager = StockInfoManager()

# ==================== å·¥å…·å‡½æ•°å®šä¹‰ ====================

@register_tool(
    name="get_company_overview",
    description="è·å–ä¸Šå¸‚å…¬å¸çš„è¯¦ç»†æ¦‚å†µä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¬å¸ä¸­è‹±æ–‡åç§°ã€ä¸»è¥ä¸šåŠ¡æè¿°ã€å…¬å¸ç®€ä»‹ã€æˆç«‹æ—¥æœŸã€ä¸Šå¸‚æ—¥æœŸã€å‘˜å·¥æ•°é‡ã€å®˜æ–¹ç½‘ç«™ã€è‘£äº‹é•¿ä¿¡æ¯ã€äº¤æ˜“æ‰€ä¿¡æ¯ç­‰ã€‚æ”¯æŒç¾è‚¡ã€æ¸¯è‚¡ã€Aè‚¡ä¸‰å¤§å¸‚åœºï¼Œè‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ä»£ç æ‰€å±å¸‚åœºã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbol": {
                "type": "string",
                "description": "è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒç¾è‚¡(å¦‚TSLA)ã€æ¸¯è‚¡(å¦‚00700)ã€Aè‚¡(å¦‚SH688111æˆ–688111)"
            },
            "market_type": {
                "type": "string",
                "description": "å¸‚åœºç±»å‹ï¼Œå¯é€‰å€¼: us(ç¾è‚¡), hk(æ¸¯è‚¡), cn(Aè‚¡)ã€‚ä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹",
                "enum": ["us", "hk", "cn"]
            },
            "save_data": {
                "type": "boolean",
                "description": "æ˜¯å¦ä¿å­˜åŸå§‹æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œé»˜è®¤False",
                "default": False
            }
        },
        "required": ["symbol"]
    }
)
def get_company_overview(symbol: str, market_type: Optional[str] = None, save_data: bool = False) -> str:
    """è·å–ä¸Šå¸‚å…¬å¸çš„æ¦‚å†µä¿¡æ¯"""
    try:
        result = _stock_manager.get_company_overview(symbol, market_type, save_data)
        
        if not result['success']:
            return f"[é”™è¯¯] {result['error']}"
        
        data = result['data']
        company = data['company_info']
        
        # æ„å»ºè¾“å‡ºä¿¡æ¯
        output = f"[æˆåŠŸ] å…¬å¸æ¦‚å†µä¿¡æ¯è·å–å®Œæˆ\n"
        output += f"è‚¡ç¥¨ä»£ç : {company.symbol} ({data['market_type'].upper()})\n"
        output += f"APIåœ°å€: {data['api_url']}\n"
        
        if result['filepath']:
            output += f"æ•°æ®æ–‡ä»¶: {result['filepath']}\n"
        
        output += f"{'=' * 60}\n\n"
        
        # ç›´æ¥æ˜¾ç¤ºæ‰€æœ‰åŸå§‹APIè¿”å›çš„å…¬å¸æ•°æ®
        company_data = data['raw_data'].get('data', {}).get('company', {})
        
        output += f"ğŸ“Š å®Œæ•´å…¬å¸ä¿¡æ¯\n"
        for key, value in company_data.items():
            if value is not None and value != "":
                # æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸ
                if key in ['established_date', 'listed_date'] and isinstance(value, (int, float)):
                    if value > 1e10:  # æ¯«ç§’æ—¶é—´æˆ³
                        value = value / 1000
                    try:
                        formatted_date = datetime.fromtimestamp(value).strftime('%Y-%m-%d')
                        output += f"{key}: {formatted_date} (æ—¶é—´æˆ³: {value})\n"
                    except:
                        output += f"{key}: {value}\n"
                else:
                    output += f"{key}: {value}\n"
        
        # é™„åŠ ä¿¡æ¯æç¤º
        if result['filepath']:
            output += f"\nğŸ’¾ å®Œæ•´æ•°æ®å·²ä¿å­˜åˆ°: {result['filepath']}"
        
        return output
        
    except Exception as e:
        return f"[é”™è¯¯] è·å–å…¬å¸æ¦‚å†µå¤±è´¥: {str(e)}"

@register_tool(
    name="detect_stock_market",
    description="æ™ºèƒ½è¯†åˆ«è‚¡ç¥¨ä»£ç æ‰€å±çš„å¸‚åœºç±»å‹ã€‚æ”¯æŒè¯†åˆ«ç¾è‚¡ï¼ˆå¦‚TSLAã€AAPLï¼‰ã€æ¸¯è‚¡ï¼ˆå¦‚00700ã€02318ï¼‰ã€Aè‚¡ï¼ˆå¦‚688111ã€000001ã€SH600000ã€SZ000002ï¼‰ç­‰ä¸åŒå¸‚åœºçš„è‚¡ç¥¨ä»£ç æ ¼å¼ï¼Œè¿”å›å¯¹åº”çš„å¸‚åœºç±»å‹æ ‡è¯†ã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbol": {
                "type": "string",
                "description": "è‚¡ç¥¨ä»£ç "
            }
        },
        "required": ["symbol"]
    }
)
def detect_stock_market(symbol: str) -> str:
    """è‡ªåŠ¨æ£€æµ‹è‚¡ç¥¨ä»£ç æ‰€å±çš„å¸‚åœºç±»å‹"""
    try:
        market_type = _stock_manager._detect_market_type(symbol)
        normalized_symbol = _stock_manager._normalize_symbol(symbol, market_type)
        
        market_names = {
            MarketType.US: "ç¾è‚¡ (NASDAQ/NYSE)",
            MarketType.HK: "æ¸¯è‚¡ (HKEX)",
            MarketType.CN: "Aè‚¡ (æ²ªæ·±äº¤æ˜“æ‰€)"
        }
        
        output = f"[æˆåŠŸ] è‚¡ç¥¨å¸‚åœºæ£€æµ‹å®Œæˆ\n"
        output += f"åŸå§‹ä»£ç : {symbol}\n"
        output += f"æ ‡å‡†åŒ–ä»£ç : {normalized_symbol}\n"
        output += f"å¸‚åœºç±»å‹: {market_type.value.upper()}\n"
        output += f"å¸‚åœºåç§°: {market_names.get(market_type, 'æœªçŸ¥')}\n"
        
        return output
        
    except Exception as e:
        return f"[é”™è¯¯] è‚¡ç¥¨å¸‚åœºæ£€æµ‹å¤±è´¥: {str(e)}"

@register_tool(
    name="get_multiple_company_overview",
    description="æ‰¹é‡è·å–å¤šä¸ªä¸Šå¸‚å…¬å¸çš„æ¦‚å†µä¿¡æ¯ï¼Œæ”¯æŒä¸€æ¬¡æ€§æŸ¥è¯¢å¤šåªè‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯ã€‚å¯ä»¥æ··åˆæŸ¥è¯¢ä¸åŒå¸‚åœºçš„è‚¡ç¥¨ï¼ˆç¾è‚¡ã€æ¸¯è‚¡ã€Aè‚¡ï¼‰ï¼Œè‡ªåŠ¨è¯†åˆ«æ¯ä¸ªè‚¡ç¥¨ä»£ç çš„å¸‚åœºç±»å‹ï¼Œè¿”å›æ±‡æ€»çš„å…¬å¸æ¦‚å†µæŠ¥å‘Šã€‚é€‚ç”¨äºæŠ•èµ„ç»„åˆåˆ†æå’Œå¤šè‚¡ç¥¨å¯¹æ¯”ç ”ç©¶ã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbols": {
                "type": "array",
                "items": {"type": "string"},
                "description": "è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚['TSLA', '00700', 'SH688111']"
            },
            "include_details": {
                "type": "boolean",
                "description": "æ˜¯å¦åŒ…å«è¯¦ç»†ä¿¡æ¯ï¼Œé»˜è®¤True",
                "default": True
            }
        },
        "required": ["symbols"]
    }
)
def get_multiple_company_overview(symbols: List[str], include_details: bool = True) -> str:
    """æ‰¹é‡è·å–å¤šä¸ªå…¬å¸çš„æ¦‚å†µä¿¡æ¯"""
    try:
        if not symbols:
            return "[é”™è¯¯] è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º"
        
        if len(symbols) > 10:
            return "[é”™è¯¯] ä¸€æ¬¡æœ€å¤šæŸ¥è¯¢10åªè‚¡ç¥¨"
        
        results = []
        for symbol in symbols:
            result = _stock_manager.get_company_overview(symbol.strip())
            results.append((symbol, result))
        
        # ç»Ÿè®¡ç»“æœ
        successful = sum(1 for _, r in results if r['success'])
        failed = len(results) - successful
        
        output = f"[æ‰¹é‡æŸ¥è¯¢] å…¬å¸æ¦‚å†µä¿¡æ¯è·å–å®Œæˆ\n"
        output += f"æŸ¥è¯¢è‚¡ç¥¨: {len(symbols)} åª\n"
        output += f"æˆåŠŸ: {successful} åªï¼Œå¤±è´¥: {failed} åª\n"
        output += f"{'=' * 60}\n\n"
        
        for i, (symbol, result) in enumerate(results, 1):
            output += f"ã€{i}ã€‘{symbol.upper()}\n"
            
            if not result['success']:
                output += f"âŒ è·å–å¤±è´¥: {result['error']}\n\n"
                continue
            
            # ç›´æ¥æ˜¾ç¤ºåŸå§‹APIè¿”å›çš„æ‰€æœ‰å…¬å¸æ•°æ®
            company_data = result['data']['raw_data'].get('data', {}).get('company', {})
            market_type = result['data']['market_type'].upper()
            output += f"âœ… {market_type}å¸‚åœº\n"
            
            # ç›´æ¥éå†æ‰€æœ‰é”®å€¼å¯¹
            for key, value in company_data.items():
                if value is not None and value != "":
                    # æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸ
                    if key in ['established_date', 'listed_date'] and isinstance(value, (int, float)):
                        if value > 1e10:  # æ¯«ç§’æ—¶é—´æˆ³
                            value = value / 1000
                        try:
                            value = datetime.fromtimestamp(value).strftime('%Y-%m-%d')
                        except:
                            pass
                    
                    output += f"{key}: {value}\n"
            
            output += f"\n"
        
        return output
        
    except Exception as e:
        return f"[é”™è¯¯] æ‰¹é‡è·å–å…¬å¸æ¦‚å†µå¤±è´¥: {str(e)}"

@register_tool(
    name="get_financial_indicators",
    description="è·å–ä¸Šå¸‚å…¬å¸çš„æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡æ•°æ®ï¼ŒåŒ…æ‹¬ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡ï¼ˆROEã€ROAã€å‡€åˆ©æ¶¦ç‡ç­‰ï¼‰ã€æˆé•¿æ€§æŒ‡æ ‡ï¼ˆè¥æ”¶å¢é•¿ç‡ã€å‡€åˆ©æ¶¦å¢é•¿ç‡ç­‰ï¼‰ã€å¿å€ºèƒ½åŠ›æŒ‡æ ‡ï¼ˆèµ„äº§è´Ÿå€ºç‡ã€æµåŠ¨æ¯”ç‡ç­‰ï¼‰ã€è¥è¿èƒ½åŠ›æŒ‡æ ‡ï¼ˆæ€»èµ„äº§å‘¨è½¬ç‡ã€å­˜è´§å‘¨è½¬ç‡ç­‰ï¼‰ã€‚æ”¯æŒå¤šæœŸæ•°æ®å¯¹æ¯”åˆ†æï¼Œç”¨äºè´¢åŠ¡å¥åº·çŠ¶å†µè¯„ä¼°å’ŒæŠ•èµ„å†³ç­–ã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbol": {
                "type": "string",
                "description": "è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒç¾è‚¡(å¦‚TSLA)ã€æ¸¯è‚¡(å¦‚00700)ã€Aè‚¡(å¦‚SH688111æˆ–688111)"
            },
            "market_type": {
                "type": "string",
                "description": "å¸‚åœºç±»å‹ï¼Œå¯é€‰å€¼: us(ç¾è‚¡), hk(æ¸¯è‚¡), cn(Aè‚¡)ã€‚ä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹",
                "enum": ["us", "hk", "cn"]
            },
            "count": {
                "type": "integer",
                "description": "è¿”å›çš„æŠ¥å‘ŠæœŸæ•°é‡ï¼Œé»˜è®¤5æœŸ",
                "default": 5,
                "minimum": 1,
                "maximum": 20
            },
            "save_data": {
                "type": "boolean",
                "description": "æ˜¯å¦ä¿å­˜åŸå§‹æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œé»˜è®¤False",
                "default": False
            }
        },
        "required": ["symbol"]
    }
)
def get_financial_indicators(symbol: str, market_type: Optional[str] = None, 
                           count: int = 5, save_data: bool = False) -> str:
    """è·å–å…¬å¸è´¢åŠ¡æŒ‡æ ‡æ•°æ®"""
    try:
        result = _stock_manager.get_financial_indicators(symbol, market_type, count, save_data)
        
        if not result['success']:
            return f"[é”™è¯¯] {result['error']}"
        
        data = result['data']
        raw_data = data['raw_data']
        
        # æ„å»ºè¾“å‡ºä¿¡æ¯
        output = f"[æˆåŠŸ] è´¢åŠ¡æŒ‡æ ‡æ•°æ®è·å–å®Œæˆ\n"
        output += f"è‚¡ç¥¨ä»£ç : {data['normalized_symbol']} ({data['market_type'].upper()})\n"
        output += f"APIåœ°å€: {data['api_url']}\n"
        
        if result['filepath']:
            output += f"æ•°æ®æ–‡ä»¶: {result['filepath']}\n"
        
        # åŸºæœ¬ä¿¡æ¯
        finance_data = raw_data.get('data', {})
        quote_name = finance_data.get('quote_name', 'æœªçŸ¥')
        currency_name = finance_data.get('currency_name', 'æœªçŸ¥')
        last_report_name = finance_data.get('last_report_name', 'æœªçŸ¥')
        
        output += f"å…¬å¸åç§°: {quote_name}\n"
        output += f"è´§å¸å•ä½: {currency_name}\n"
        output += f"æœ€æ–°æŠ¥å‘ŠæœŸ: {last_report_name}\n"
        output += f"{'=' * 80}\n\n"
        
        # è´¢åŠ¡æŒ‡æ ‡åˆ—è¡¨
        indicator_list = finance_data.get('list', [])
        
        if not indicator_list:
            output += "ğŸ“Š æ— è´¢åŠ¡æŒ‡æ ‡æ•°æ®\n"
            return output
        
        # æ˜¾ç¤ºæ¯ä¸ªæŠ¥å‘ŠæœŸçš„æ‰€æœ‰æŒ‡æ ‡
        for i, period_data in enumerate(indicator_list, 1):
            report_date = period_data.get('report_date')
            report_name = period_data.get('report_name', 'æœªçŸ¥')
            ctime = period_data.get('ctime')
            
            # è½¬æ¢æ—¶é—´æˆ³
            if report_date:
                try:
                    if report_date > 1e10:
                        report_date = report_date / 1000
                    formatted_date = datetime.fromtimestamp(report_date).strftime('%Y-%m-%d')
                except:
                    formatted_date = str(report_date)
            else:
                formatted_date = "æœªçŸ¥"
            
            if ctime:
                try:
                    if ctime > 1e10:
                        ctime = ctime / 1000
                    formatted_ctime = datetime.fromtimestamp(ctime).strftime('%Y-%m-%d %H:%M:%S')
                except:
                    formatted_ctime = str(ctime)
            else:
                formatted_ctime = "æœªçŸ¥"
            
            output += f"ğŸ“Š ã€{i}ã€‘{report_name} ({formatted_date})\n"
            output += f"å‘å¸ƒæ—¶é—´: {formatted_ctime}\n"
            output += f"{'-' * 60}\n"
            
            # æ˜¾ç¤ºæ‰€æœ‰æŒ‡æ ‡
            for key, value in period_data.items():
                if key not in ['report_date', 'report_name', 'ctime']:
                    # å¤„ç†æ•°ç»„ç±»å‹çš„å€¼ï¼ˆé€šå¸¸æ˜¯ [å½“å‰å€¼, åŒæ¯”å˜åŒ–ç‡]ï¼‰
                    if isinstance(value, list) and len(value) >= 2:
                        current_value = value[0]
                        change_rate = value[1]
                        
                        # æ ¼å¼åŒ–å˜åŒ–ç‡ä¸ºç™¾åˆ†æ¯”
                        if isinstance(change_rate, (int, float)):
                            if abs(change_rate) < 1:  # å°æ•°å½¢å¼çš„å˜åŒ–ç‡
                                change_rate_str = f"{change_rate * 100:.2f}%"
                            else:  # å·²ç»æ˜¯ç™¾åˆ†æ¯”å½¢å¼
                                change_rate_str = f"{change_rate:.2f}%"
                        else:
                            change_rate_str = str(change_rate)
                        
                        output += f"{key}: {current_value} (åŒæ¯”: {change_rate_str})\n"
                    else:
                        output += f"{key}: {value}\n"
            
            output += f"\n"
        
        # é™„åŠ ä¿¡æ¯æç¤º
        if result['filepath']:
            output += f"ğŸ’¾ å®Œæ•´æ•°æ®å·²ä¿å­˜åˆ°: {result['filepath']}"
        
        return output
        
    except Exception as e:
        return f"[é”™è¯¯] è·å–è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {str(e)}"

@register_tool(
    name="get_income_statement",
    description="è·å–ä¸Šå¸‚å…¬å¸çš„åˆ©æ¶¦è¡¨ï¼ˆæŸç›Šè¡¨ï¼‰è¯¦ç»†æ•°æ®ï¼ŒåŒ…æ‹¬è¥ä¸šæ”¶å…¥ã€è¥ä¸šæˆæœ¬ã€æ¯›åˆ©æ¶¦ã€è¥ä¸šåˆ©æ¶¦ã€åˆ©æ¶¦æ€»é¢ã€å‡€åˆ©æ¶¦ã€æ¯è‚¡æ”¶ç›Šç­‰æ ¸å¿ƒæŸç›Šé¡¹ç›®ã€‚æ”¯æŒå¤šä¸ªæŠ¥å‘ŠæœŸçš„å†å²æ•°æ®æŸ¥è¯¢ï¼Œç”¨äºåˆ†æå…¬å¸ç›ˆåˆ©èƒ½åŠ›å˜åŒ–è¶‹åŠ¿å’Œç»è¥ä¸šç»©è¡¨ç°ã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbol": {
                "type": "string",
                "description": "è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒç¾è‚¡(å¦‚TSLA)ã€æ¸¯è‚¡(å¦‚00700)ã€Aè‚¡(å¦‚SH688111æˆ–688111)"
            },
            "market_type": {
                "type": "string",
                "description": "å¸‚åœºç±»å‹ï¼Œå¯é€‰å€¼: us(ç¾è‚¡), hk(æ¸¯è‚¡), cn(Aè‚¡)ã€‚ä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹",
                "enum": ["us", "hk", "cn"]
            },
            "count": {
                "type": "integer",
                "description": "è¿”å›çš„æŠ¥å‘ŠæœŸæ•°é‡ï¼Œé»˜è®¤5æœŸ",
                "default": 5,
                "minimum": 1,
                "maximum": 20
            },
            "save_data": {
                "type": "boolean",
                "description": "æ˜¯å¦ä¿å­˜åŸå§‹æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œé»˜è®¤False",
                "default": False
            }
        },
        "required": ["symbol"]
    }
)
def get_income_statement(symbol: str, market_type: Optional[str] = None, 
                        count: int = 5, save_data: bool = False) -> str:
    """è·å–å…¬å¸åˆ©æ¶¦è¡¨æ•°æ®"""
    try:
        result = _stock_manager.get_income_statement(symbol, market_type, count, save_data)
        
        if not result['success']:
            return f"[é”™è¯¯] {result['error']}"
        
        data = result['data']
        raw_data = data['raw_data']
        
        # æ„å»ºè¾“å‡ºä¿¡æ¯
        output = f"[æˆåŠŸ] åˆ©æ¶¦è¡¨æ•°æ®è·å–å®Œæˆ\n"
        output += f"è‚¡ç¥¨ä»£ç : {data['normalized_symbol']} ({data['market_type'].upper()})\n"
        output += f"APIåœ°å€: {data['api_url']}\n"
        
        if result['filepath']:
            output += f"æ•°æ®æ–‡ä»¶: {result['filepath']}\n"
        
        # åŸºæœ¬ä¿¡æ¯
        finance_data = raw_data.get('data', {})
        quote_name = finance_data.get('quote_name', 'æœªçŸ¥')
        currency_name = finance_data.get('currency_name', 'æœªçŸ¥')
        last_report_name = finance_data.get('last_report_name', 'æœªçŸ¥')
        
        output += f"å…¬å¸åç§°: {quote_name}\n"
        output += f"è´§å¸å•ä½: {currency_name}\n"
        output += f"æœ€æ–°æŠ¥å‘ŠæœŸ: {last_report_name}\n"
        output += f"{'=' * 80}\n\n"
        
        # åˆ©æ¶¦è¡¨åˆ—è¡¨
        income_list = finance_data.get('list', [])
        
        if not income_list:
            output += "ğŸ“Š æ— åˆ©æ¶¦è¡¨æ•°æ®\n"
            return output
        
        # æ˜¾ç¤ºæ¯ä¸ªæŠ¥å‘ŠæœŸçš„æ‰€æœ‰åˆ©æ¶¦è¡¨é¡¹ç›®
        for i, period_data in enumerate(income_list, 1):
            report_date = period_data.get('report_date')
            report_name = period_data.get('report_name', 'æœªçŸ¥')
            ctime = period_data.get('ctime')
            
            # è½¬æ¢æ—¶é—´æˆ³
            if report_date:
                try:
                    if report_date > 1e10:
                        report_date = report_date / 1000
                    formatted_date = datetime.fromtimestamp(report_date).strftime('%Y-%m-%d')
                except:
                    formatted_date = str(report_date)
            else:
                formatted_date = "æœªçŸ¥"
            
            if ctime:
                try:
                    if ctime > 1e10:
                        ctime = ctime / 1000
                    formatted_ctime = datetime.fromtimestamp(ctime).strftime('%Y-%m-%d %H:%M:%S')
                except:
                    formatted_ctime = str(ctime)
            else:
                formatted_ctime = "æœªçŸ¥"
            
            output += f"ğŸ“Š ã€{i}ã€‘{report_name} ({formatted_date})\n"
            output += f"å‘å¸ƒæ—¶é—´: {formatted_ctime}\n"
            output += f"{'-' * 60}\n"
            
            # æ˜¾ç¤ºæ‰€æœ‰åˆ©æ¶¦è¡¨é¡¹ç›®
            for key, value in period_data.items():
                if key not in ['report_date', 'report_name', 'ctime']:
                    # å¤„ç†æ•°ç»„ç±»å‹çš„å€¼ï¼ˆé€šå¸¸æ˜¯ [å½“å‰å€¼, åŒæ¯”å˜åŒ–ç‡]ï¼‰
                    if isinstance(value, list) and len(value) >= 2:
                        current_value = value[0]
                        change_rate = value[1]
                        
                        # æ ¼å¼åŒ–é‡‘é¢ï¼ˆå¦‚æœæ˜¯å¤§æ•°å­—ï¼‰
                        if isinstance(current_value, (int, float)) and abs(current_value) > 1000000:
                            if abs(current_value) > 1e8:
                                current_value_str = f"{current_value/1e8:.2f}äº¿"
                            elif abs(current_value) > 1e4:
                                current_value_str = f"{current_value/1e4:.2f}ä¸‡"
                            else:
                                current_value_str = str(current_value)
                        else:
                            current_value_str = str(current_value)
                        
                        # æ ¼å¼åŒ–å˜åŒ–ç‡ä¸ºç™¾åˆ†æ¯”
                        if isinstance(change_rate, (int, float)):
                            if abs(change_rate) < 1:  # å°æ•°å½¢å¼çš„å˜åŒ–ç‡
                                change_rate_str = f"{change_rate * 100:.2f}%"
                            else:  # å·²ç»æ˜¯ç™¾åˆ†æ¯”å½¢å¼
                                change_rate_str = f"{change_rate:.2f}%"
                        else:
                            change_rate_str = str(change_rate)
                        
                        output += f"{key}: {current_value_str} (åŒæ¯”: {change_rate_str})\n"
                    else:
                        # å•ä¸ªå€¼ï¼Œä¹Ÿå°è¯•æ ¼å¼åŒ–é‡‘é¢
                        if isinstance(value, (int, float)) and abs(value) > 1000000:
                            if abs(value) > 1e8:
                                value_str = f"{value/1e8:.2f}äº¿"
                            elif abs(value) > 1e4:
                                value_str = f"{value/1e4:.2f}ä¸‡"
                            else:
                                value_str = str(value)
                        else:
                            value_str = str(value)
                        
                        output += f"{key}: {value_str}\n"
            
            output += f"\n"
        
        # é™„åŠ ä¿¡æ¯æç¤º
        if result['filepath']:
            output += f"ğŸ’¾ å®Œæ•´æ•°æ®å·²ä¿å­˜åˆ°: {result['filepath']}"
        
        return output
        
    except Exception as e:
        return f"[é”™è¯¯] è·å–åˆ©æ¶¦è¡¨å¤±è´¥: {str(e)}"

@register_tool(
    name="list_supported_markets",
    description="åˆ—å‡ºå½“å‰å·¥å…·æ”¯æŒçš„æ‰€æœ‰è‚¡ç¥¨å¸‚åœºç±»å‹åŠå…¶è¯¦ç»†è¯´æ˜ï¼ŒåŒ…æ‹¬å¸‚åœºä»£ç ã€å¸‚åœºåç§°ã€æ”¯æŒçš„è‚¡ç¥¨ä»£ç æ ¼å¼ç¤ºä¾‹ç­‰ä¿¡æ¯ã€‚å¸®åŠ©ç”¨æˆ·äº†è§£å¯ä»¥æŸ¥è¯¢å“ªäº›å¸‚åœºçš„è‚¡ç¥¨æ•°æ®ã€‚",
    schema={
        "type": "object",
        "properties": {}
    }
)
def list_supported_markets() -> str:
    """åˆ—å‡ºæ”¯æŒçš„è‚¡ç¥¨å¸‚åœºç±»å‹"""
    try:
        output = f"[æˆåŠŸ] æ”¯æŒçš„è‚¡ç¥¨å¸‚åœºç±»å‹\n"
        output += f"{'=' * 40}\n\n"
        
        markets = [
            {
                "code": "us",
                "name": "ç¾è‚¡",
                "description": "ç¾å›½çº³æ–¯è¾¾å…‹ã€çº½çº¦è¯åˆ¸äº¤æ˜“æ‰€",
                "example": "TSLA, AAPL, MSFT"
            },
            {
                "code": "hk", 
                "name": "æ¸¯è‚¡",
                "description": "é¦™æ¸¯äº¤æ˜“æ‰€",
                "example": "00700, 00941, 09988"
            },
            {
                "code": "cn",
                "name": "Aè‚¡",
                "description": "ä¸Šæµ·ã€æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€",
                "example": "SH600036, SZ000001, 688111"
            }
        ]
        
        for market in markets:
            output += f"ğŸ¢ {market['name']} ({market['code'].upper()})\n"
            output += f"   äº¤æ˜“æ‰€: {market['description']}\n"
            output += f"   ä»£ç ç¤ºä¾‹: {market['example']}\n\n"
        
        output += f"ğŸ’¡ ä½¿ç”¨è¯´æ˜:\n"
        output += f"- å¤§éƒ¨åˆ†æƒ…å†µä¸‹å¯ä»¥è‡ªåŠ¨æ£€æµ‹å¸‚åœºç±»å‹ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å®š\n"
        output += f"- Aè‚¡æ”¯æŒå¸¦å‰ç¼€(SH/SZ)å’Œä¸å¸¦å‰ç¼€çš„æ ¼å¼\n"
        output += f"- æ¸¯è‚¡ä»£ç é€šå¸¸ä¸º5ä½æ•°å­—ï¼Œä»¥0å¼€å¤´\n"
        output += f"- ç¾è‚¡ä»£ç ä¸ºå­—æ¯ç»„åˆï¼Œå¦‚TSLAã€AAPLç­‰\n"
        
        return output
        
    except Exception as e:
        return f"[é”™è¯¯] è·å–å¸‚åœºåˆ—è¡¨å¤±è´¥: {str(e)}"

@register_tool(
    name="get_balance_sheet",
    description="è·å–ä¸Šå¸‚å…¬å¸çš„èµ„äº§è´Ÿå€ºè¡¨è¯¦ç»†æ•°æ®ï¼ŒåŒ…æ‹¬æ€»èµ„äº§ã€æµåŠ¨èµ„äº§ã€éæµåŠ¨èµ„äº§ã€æ€»è´Ÿå€ºã€æµåŠ¨è´Ÿå€ºã€éæµåŠ¨è´Ÿå€ºã€è‚¡ä¸œæƒç›Šç­‰æ ¸å¿ƒè´¢åŠ¡çŠ¶å†µæŒ‡æ ‡ã€‚æ”¯æŒå¤šä¸ªæŠ¥å‘ŠæœŸçš„å†å²æ•°æ®æŸ¥è¯¢ï¼Œç”¨äºåˆ†æå…¬å¸èµ„äº§ç»“æ„ã€è´Ÿå€ºæ°´å¹³å’Œè´¢åŠ¡ç¨³å®šæ€§ã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbol": {
                "type": "string",
                "description": "è‚¡ç¥¨ä»£ç ï¼Œå¦‚ TSLAã€688111ã€00700"
            },
            "count": {
                "type": "integer",
                "description": "è·å–æœŸæ•°ï¼Œé»˜è®¤5æœŸ",
                "default": 5
            },
            "save_to_file": {
                "type": "boolean",
                "description": "æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶",
                "default": False
            },
            "file_path": {
                "type": "string",
                "description": "ä¿å­˜æ–‡ä»¶è·¯å¾„ï¼ˆéœ€è¦save_to_file=Trueï¼‰"
            }
        },
        "required": ["symbol"]
    }
)
def get_balance_sheet(symbol: str, count: int = 5, save_to_file: bool = False, file_path: Optional[str] = None) -> str:
    """è·å–å…¬å¸èµ„äº§è´Ÿå€ºè¡¨æ•°æ®"""
    try:
        # æ£€æµ‹å¸‚åœºç±»å‹å¹¶æ ‡å‡†åŒ–ä»£ç 
        market_type = _stock_manager._detect_market_type(symbol)
        normalized_symbol = _stock_manager._normalize_symbol(symbol, market_type)
        
        market_map = {
            MarketType.US: "us",
            MarketType.HK: "hk", 
            MarketType.CN: "cn"
        }
        market = market_map[market_type]
        
        # æ„é€ API URL
        timestamp = int(time.time() * 1000)
        url = f"https://stock.xueqiu.com/v5/stock/finance/{market}/balance.json"
        
        params = {
            'symbol': normalized_symbol,
            'type': 'all',
            'is_detail': 'true',
            'count': str(count),
            'timestamp': str(timestamp)
        }
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'accept': 'application/json, text/plain, */*',
            'accept-language': 'zh-CN,zh;q=0.9,ko;q=0.8,en-US;q=0.7,en;q=0.6',
            'cache-control': 'no-cache',
            'origin': 'https://xueqiu.com',
            'referer': f'https://xueqiu.com/snowman/S/{normalized_symbol}/detail',
            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
            'cookie': 's=be12bcx3pb; cookiesu=971748192631827; device_id=afda57cfe6697001d99fa8895d7a8922; u=971748192631827; Hm_lvt_1db88642e346389874251b5a1eded6e3=1748192633,1749565221; HMACCOUNT=73EFE7072B2EF8EE; xq_a_token=b7259d09435458cc3f1a963479abb270a1a016ce; xqat=b7259d09435458cc3f1a963479abb270a1a016ce; xq_r_token=28108bfa1d92ac8a46bbb57722633746218621a3; xq_id_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ1aWQiOi0xLCJpc3MiOiJ1YyIsImV4cCI6MTc1MjU0MTk4OCwiY3RtIjoxNzQ5OTk0MzEyODE0LCJjaWQiOiJkOWQwbjRBWnVwIn0.jNWjZYg_wpiX1GgMAlx7hE9ZE8pTjQg6V5NgsM7O2vSbzM_yE4np01eywM_aKem3L0sh3bMqgbpZT8IG0L61oJ7yEV84aO6wajvfSgP8NOtkNJxDk6ljYG57-fgau9Ig1Vpi49_Md-fM4BXQeza0sgHXnBLnvv7LyVks5Z1puo4mr_pGIyKYr_o5MtWRFGNZBRpDtTQ0SgYn8pQWJ9ceu9EojXvYeelq4hny4Gocgj6yvnaInlyimJA3own6mb5d0a067ypFnZ9YP3UG_jcBndeXn5OX1wNmeBcHgGTwH_vN33bo6vjb1Nqhu7v2Hb4WpLrjyK8POAFUjivQ7THdkA; Hm_lpvt_1db88642e346389874251b5a1eded6e3=1749994377; ssxmod_itna=YqUxnDcDBC0QiQ=i7NitYiOqDQK4ijKQDXDUqMq7tDRDFqApxDH8mrF5stfB=8YKnDG=45aY5D/zG7eDZDG9dDqx0ErXQA7Tthe9G7gqpPfl0Y4hkW80GSYaYQI=RxYifUzSc65c7eGImDG2DYoDCqDS0DD9R2GrDYYfDBYD74G+DDeDixbDGuuP2DDFRWbdclNQiW+PueDE000a0DDgjPD1QPWrulNqla4D0LWDfR0WleqxxY=DQwOQFoTDjR9W7KGyQeGWi8RjuKGuSZixphuNqPqU=RDSzCLxW7eM+BxPfA6hznGxngxNAD4EsPYs3AxYA4qY5=nQkxDic5Kb2rBqK4U2atq1UriXYAm=e52YI6DKrUxr/Dgpw1nwKAG5mDIA03iiGGDK3X3YD; ssxmod_itna2=YqUxnDcDBC0QiQ=i7NitYiOqDQK4ijKQDXDUqMq7tDRDFqApxDH8mrF5stfB=8YKnDG=45a7eDAQf7G+C=fQD03qe8G3TPDBMpP4WMYZ5y53fY=RcKkBFEhWq3m+7DHhYA+sYgERHupq29iQ4YMLxWw6Hebfu80DRAbQh+CiujLr2fkrnKe4DpCXx5W5eWj3lSf+Xzeh4wO0HQG2K8Gj5m8rZ7MhW=TQkrYc5K0rk57fPvfhSzTF8yQcKnL4Qwg6EgbUU7Zxipai6Kpi2uZxNLUdu2UiCM8g4T/C=cR18=7m5covxo0sEYGiCmxnrZ0pV/bDNuqzir9GE+bZKGEQRY9GPLAtQDNfGNW0qbD40BPsiKPD'
        }
        
                # ä½¿ç”¨web_scraperå‘é€APIè¯·æ±‚
        if _web_scraper is None:
            return f"[é”™è¯¯] WebæŠ“å–å·¥å…·å®ä¾‹ä¸å¯ç”¨"
        
        # ç›´æ¥æ„é€ å®Œæ•´URL
        param_str = "&".join([f"{k}={v}" for k, v in params.items()])
        full_url = f"{url}?{param_str}"
        
        result = _web_scraper.api_request(
            url=full_url,
            method="GET",
            headers=headers,
            timeout=30
        )
        
        if not result['success']:
            return f"[é”™è¯¯] APIè¯·æ±‚å¤±è´¥: {result['error']}\nURL: {full_url}"
        
        if not result['is_json']:
            return f"[é”™è¯¯] å“åº”ä¸æ˜¯JSONæ ¼å¼\nå“åº”å†…å®¹: {result.get('content', '')[:500]}"
        
        data = result['json']
        
        # æ£€æŸ¥APIè¿”å›çš„é”™è¯¯
        if 'error_code' in data and data.get('error_code') != 0:
            return f"[é”™è¯¯] APIè¿”å›é”™è¯¯: {data.get('error_description', 'æœªçŸ¥é”™è¯¯')}"
        
        quote_data = data.get('data', {})
        company_name = quote_data.get('quote_name', 'æœªçŸ¥å…¬å¸')
        currency = quote_data.get('currency_name', 'æœªçŸ¥å¸ç§')
        balance_list = quote_data.get('list', [])
        
        if not balance_list:
            return f"[é”™è¯¯] æœªè·å–åˆ°{symbol}çš„èµ„äº§è´Ÿå€ºè¡¨æ•°æ®"
        
        result = f"ğŸ“Š {company_name}({symbol}) èµ„äº§è´Ÿå€ºè¡¨\n"
        result += f"ğŸ’± å¸ç§: {currency}\n"
        result += f"ğŸ“ˆ æœŸæ•°: {len(balance_list)}\n"
        result += "=" * 60 + "\n\n"
        
        for i, period_data in enumerate(balance_list):
            report_name = period_data.get('report_name', 'æœªçŸ¥æœŸé—´')
            report_timestamp = period_data.get('report_date')
            
            result += f"ğŸ“… ã€{report_name}ã€‘"
            if report_timestamp:
                report_date = datetime.fromtimestamp(report_timestamp / 1000).strftime('%Y-%m-%d')
                result += f" ({report_date})"
            result += "\n"
            result += "-" * 40 + "\n"
            
            # æ˜¾ç¤ºæ‰€æœ‰åŸå§‹æ•°æ®
            for key, value in period_data.items():
                if key in ['report_date', 'report_name', 'ctime']:
                    continue
                    
                if isinstance(value, list) and len(value) >= 2:
                    amount, change_rate = value[0], value[1]
                    if amount is not None:
                        # æ ¼å¼åŒ–é‡‘é¢
                        if abs(amount) >= 1e8:
                            formatted_amount = f"{amount/1e8:.2f}äº¿"
                        elif abs(amount) >= 1e4:
                            formatted_amount = f"{amount/1e4:.2f}ä¸‡"
                        else:
                            formatted_amount = f"{amount:.2f}"
                        
                        # æ ¼å¼åŒ–å˜åŒ–ç‡
                        if change_rate is not None:
                            change_str = f" (åŒæ¯”{'+' if change_rate > 0 else ''}{change_rate*100:.2f}%)"
                        else:
                            change_str = ""
                        
                        result += f"  {key}: {formatted_amount}{change_str}\n"
                    else:
                        result += f"  {key}: æ— æ•°æ®\n"
                else:
                    if value is not None:
                        result += f"  {key}: {value}\n"
                    else:
                        result += f"  {key}: æ— æ•°æ®\n"
            
            result += "\n"
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if save_to_file:
            if not file_path:
                timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_path = f"{symbol}_balance_sheet_{timestamp_str}.txt"
            
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(result)
                result += f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {file_path}"
            except Exception as e:
                result += f"\nâŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}"
        
        return result
        
    except Exception as e:
        return f"[é”™è¯¯] è·å–èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {str(e)}"

@register_tool(
    name="get_multiple_balance_sheet", 
    description="æ‰¹é‡è·å–å¤šä¸ªä¸Šå¸‚å…¬å¸çš„èµ„äº§è´Ÿå€ºè¡¨æ•°æ®ï¼Œæ”¯æŒä¸€æ¬¡æ€§æŸ¥è¯¢å¤šåªè‚¡ç¥¨çš„è´¢åŠ¡çŠ¶å†µã€‚å¯ä»¥æ··åˆæŸ¥è¯¢ä¸åŒå¸‚åœºçš„è‚¡ç¥¨ï¼Œè‡ªåŠ¨è¯†åˆ«å¸‚åœºç±»å‹ï¼Œè¿”å›æ±‡æ€»çš„èµ„äº§è´Ÿå€ºè¡¨åˆ†ææŠ¥å‘Šã€‚é€‚ç”¨äºæŠ•èµ„ç»„åˆçš„è´¢åŠ¡å¥åº·çŠ¶å†µå¯¹æ¯”åˆ†æå’Œé£é™©è¯„ä¼°ã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbols": {
                "type": "array",
                "items": {"type": "string"},
                "description": "è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚['TSLA', '00700', 'SH688111']"
            },
            "count": {
                "type": "integer", 
                "description": "æ¯åªè‚¡ç¥¨è·å–çš„æœŸæ•°ï¼Œé»˜è®¤3æœŸ",
                "default": 3
            },
            "include_details": {
                "type": "boolean",
                "description": "æ˜¯å¦åŒ…å«è¯¦ç»†æ•°æ®ï¼Œé»˜è®¤Falseï¼ˆä»…æ˜¾ç¤ºå…³é”®æŒ‡æ ‡ï¼‰",
                "default": False
            }
        },
        "required": ["symbols"]
    }
)
def get_multiple_balance_sheet(symbols: List[str], count: int = 3, include_details: bool = False) -> str:
    """æ‰¹é‡è·å–å¤šä¸ªå…¬å¸çš„èµ„äº§è´Ÿå€ºè¡¨æ•°æ®"""
    try:
        if not symbols:
            return "[é”™è¯¯] è¯·æä¾›è‡³å°‘ä¸€ä¸ªè‚¡ç¥¨ä»£ç "
        
        results = []
        success_count = 0
        
        for symbol in symbols:
            try:
                # æ£€æµ‹å¸‚åœºç±»å‹å¹¶æ ‡å‡†åŒ–ä»£ç 
                market_type = _stock_manager._detect_market_type(symbol)
                normalized_symbol = _stock_manager._normalize_symbol(symbol, market_type)
                
                market_map = {
                    MarketType.US: "us",
                    MarketType.HK: "hk",
                    MarketType.CN: "cn"
                }
                market = market_map[market_type]
                
                # æ„é€ API URL
                timestamp = int(time.time() * 1000)
                url = f"https://stock.xueqiu.com/v5/stock/finance/{market}/balance.json"
                
                params = {
                    'symbol': normalized_symbol,
                    'type': 'all',
                    'is_detail': 'true',
                    'count': str(count),
                    'timestamp': str(timestamp)
                }
                
                # è®¾ç½®è¯·æ±‚å¤´
                headers = {
                    'accept': 'application/json, text/plain, */*',
                    'accept-language': 'zh-CN,zh;q=0.9,ko;q=0.8,en-US;q=0.7,en;q=0.6',
                    'cache-control': 'no-cache',
                    'origin': 'https://xueqiu.com',
                    'referer': f'https://xueqiu.com/snowman/S/{normalized_symbol}/detail',
                    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
                    'cookie': 's=be12bcx3pb; cookiesu=971748192631827; device_id=afda57cfe6697001d99fa8895d7a8922; u=971748192631827; Hm_lvt_1db88642e346389874251b5a1eded6e3=1748192633,1749565221; HMACCOUNT=73EFE7072B2EF8EE; xq_a_token=b7259d09435458cc3f1a963479abb270a1a016ce; xqat=b7259d09435458cc3f1a963479abb270a1a016ce; xq_r_token=28108bfa1d92ac8a46bbb57722633746218621a3; xq_id_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ1aWQiOi0xLCJpc3MiOiJ1YyIsImV4cCI6MTc1MjU0MTk4OCwiY3RtIjoxNzQ5OTk0MzEyODE0LCJjaWQiOiJkOWQwbjRBWnVwIn0.jNWjZYg_wpiX1GgMAlx7hE9ZE8pTjQg6V5NgsM7O2vSbzM_yE4np01eywM_aKem3L0sh3bMqgbpZT8IG0L61oJ7yEV84aO6wajvfSgP8NOtkNJxDk6ljYG57-fgau9Ig1Vpi49_Md-fM4BXQeza0sgHXnBLnvv7LyVks5Z1puo4mr_pGIyKYr_o5MtWRFGNZBRpDtTQ0SgYn8pQWJ9ceu9EojXvYeelq4hny4Gocgj6yvnaInlyimJA3own6mb5d0a067ypFnZ9YP3UG_jcBndeXn5OX1wNmeBcHgGTwH_vN33bo6vjb1Nqhu7v2Hb4WpLrjyK8POAFUjivQ7THdkA; Hm_lpvt_1db88642e346389874251b5a1eded6e3=1749994377; ssxmod_itna=YqUxnDcDBC0QiQ=i7NitYiOqDQK4ijKQDXDUqMq7tDRDFqApxDH8mrF5stfB=8YKnDG=45aY5D/zG7eDZDG9dDqx0ErXQA7Tthe9G7gqpPfl0Y4hkW80GSYaYQI=RxYifUzSc65c7eGImDG2DYoDCqDS0DD9R2GrDYYfDBYD74G+DDeDixbDGuuP2DDFRWbdclNQiW+PueDE000a0DDgjPD1QPWrulNqla4D0LWDfR0WleqxxY=DQwOQFoTDjR9W7KGyQeGWi8RjuKGuSZixphuNqPqU=RDSzCLxW7eM+BxPfA6hznGxngxNAD4EsPYs3AxYA4qY5=nQkxDic5Kb2rBqK4U2atq1UriXYAm=e52YI6DKrUxr/Dgpw1nwKAG5mDIA03iiGGDK3X3YD; ssxmod_itna2=YqUxnDcDBC0QiQ=i7NitYiOqDQK4ijKQDXDUqMq7tDRDFqApxDH8mrF5stfB=8YKnDG=45a7eDAQf7G+C=fQD03qe8G3TPDBMpP4WMYZ5y53fY=RcKkBFEhWq3m+7DHhYA+sYgERHupq29iQ4YMLxWw6Hebfu80DRAbQh+CiujLr2fkrnKe4DpCXx5W5eWj3lSf+Xzeh4wO0HQG2K8Gj5m8rZ7MhW=TQkrYc5K0rk57fPvfhSzTF8yQcKnL4Qwg6EgbUU7Zxipai6Kpi2uZxNLUdu2UiCM8g4T/C=cR18=7m5covxo0sEYGiCmxnrZ0pV/bDNuqzir9GE+bZKGEQRY9GPLAtQDNfGNW0qbD40BPsiKPD'
                }
                
                # ä½¿ç”¨web_scraperå‘é€APIè¯·æ±‚
                if _web_scraper is None:
                    results.append(f"âŒ {symbol}: WebæŠ“å–å·¥å…·å®ä¾‹ä¸å¯ç”¨")
                    continue
                
                result = _web_scraper.api_request(
                    url=url,
                    method="GET",
                    headers=headers,
                    data=params,
                    timeout=30
                )
                
                if not result['success']:
                    results.append(f"âŒ {symbol}: APIè¯·æ±‚å¤±è´¥ - {result['error']}")
                    continue
                
                if not result['is_json']:
                    results.append(f"âŒ {symbol}: å“åº”ä¸æ˜¯JSONæ ¼å¼")
                    continue
                
                data = result['json']
                
                if data.get('error_code') != 0:
                    results.append(f"âŒ {symbol}: {data.get('error_description', 'æœªçŸ¥é”™è¯¯')}")
                    continue
                
                quote_data = data.get('data', {})
                company_name = quote_data.get('quote_name', 'æœªçŸ¥å…¬å¸')
                currency = quote_data.get('currency_name', 'æœªçŸ¥å¸ç§')
                balance_list = quote_data.get('list', [])
                
                if not balance_list:
                    results.append(f"âŒ {symbol}: æœªè·å–åˆ°èµ„äº§è´Ÿå€ºè¡¨æ•°æ®")
                    continue
                
                # å¤„ç†èµ„äº§è´Ÿå€ºè¡¨æ•°æ®
                company_result = f"ğŸ“Š {company_name}({symbol}) - {currency}\n"
                company_result += "-" * 50 + "\n"
                
                # åªè·å–æœ€æ–°æœŸçš„æ•°æ®
                period_data = balance_list[0]
                report_name = period_data.get('report_name', 'æœªçŸ¥æœŸé—´')
                report_timestamp = period_data.get('report_date')
                
                period_title = f"ğŸ“… {report_name}"
                if report_timestamp:
                    report_date = datetime.fromtimestamp(report_timestamp / 1000).strftime('%Y-%m-%d')
                    period_title += f" ({report_date})"
                
                company_result += f"{period_title}\n"
                
                # æ˜¾ç¤ºæ‰€æœ‰åŸå§‹æ•°æ®
                for key, value in period_data.items():
                    if key in ['report_date', 'report_name', 'ctime']:
                        continue
                        
                    if isinstance(value, list) and len(value) >= 2:
                        amount, change_rate = value[0], value[1]
                        if amount is not None:
                            # æ ¼å¼åŒ–é‡‘é¢
                            if abs(amount) >= 1e8:
                                formatted_amount = f"{amount/1e8:.2f}äº¿"
                            elif abs(amount) >= 1e4:
                                formatted_amount = f"{amount/1e4:.2f}ä¸‡"
                            else:
                                formatted_amount = f"{amount:.2f}"
                            
                            # æ ¼å¼åŒ–å˜åŒ–ç‡
                            if change_rate is not None:
                                change_str = f" (åŒæ¯”{'+' if change_rate > 0 else ''}{change_rate*100:.2f}%)"
                            else:
                                change_str = ""
                            
                            company_result += f"  {key}: {formatted_amount}{change_str}\n"
                        else:
                            company_result += f"  {key}: æ— æ•°æ®\n"
                    else:
                        if value is not None:
                            company_result += f"  {key}: {value}\n"
                        else:
                            company_result += f"  {key}: æ— æ•°æ®\n"
                
                results.append(company_result)
                success_count += 1
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.5)
                
            except Exception as e:
                results.append(f"âŒ {symbol}: å¤„ç†å¤±è´¥ - {str(e)}")
        
        # ç”Ÿæˆæ±‡æ€»ç»“æœ
        output = f"ğŸ“ˆ æ‰¹é‡èµ„äº§è´Ÿå€ºè¡¨æŸ¥è¯¢ç»“æœ\n"
        output += f"{'=' * 60}\n"
        output += f"æ€»è®¡: {len(symbols)}åªè‚¡ç¥¨, æˆåŠŸ: {success_count}åª, å¤±è´¥: {len(symbols) - success_count}åª\n\n"
        
        for result in results:
            output += result + "\n"
        
        return output
        
    except Exception as e:
        return f"[é”™è¯¯] æ‰¹é‡è·å–èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {str(e)}"

@register_tool(
    name="get_stock_price_and_technical_analysis",
    description="è·å–è‚¡ç¥¨çš„å®æ—¶è‚¡ä»·ä¿¡æ¯å’Œå…¨é¢çš„æŠ€æœ¯æŒ‡æ ‡åˆ†æã€‚åŒ…æ‹¬å½“å‰è‚¡ä»·ã€æ¶¨è·Œå¹…ã€æˆäº¤é‡ç­‰åŸºç¡€æ•°æ®ï¼Œä»¥åŠç§»åŠ¨å¹³å‡çº¿ç³»ç»Ÿï¼ˆMA5/10/20/60ï¼‰ã€MACDæŒ‡æ ‡ã€KDJéšæœºæŒ‡æ ‡ã€å¸ƒæ—å¸¦ï¼ˆBOLLï¼‰ã€SARæŠ›ç‰©çº¿æŒ‡æ ‡ç­‰å¤šç§æŠ€æœ¯åˆ†æå·¥å…·ã€‚æä¾›ä¸“ä¸šçš„æŠ€æœ¯åˆ†ææ‘˜è¦å’ŒæŠ•èµ„å‚è€ƒå»ºè®®ï¼Œæ”¯æŒç¾è‚¡ã€æ¸¯è‚¡ã€Aè‚¡å¸‚åœºã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbol": {
                "type": "string",
                "description": "è‚¡ç¥¨ä»£ç ï¼Œå¦‚ TSLAã€688111ã€00700"
            },
            "days": {
                "type": "integer",
                "description": "è·å–å¤šå°‘å¤©çš„Kçº¿æ•°æ®ï¼Œé»˜è®¤365å¤©",
                "default": 365,
                "minimum": 30,
                "maximum": 1000
            }
        },
        "required": ["symbol"]
    }
)
def get_technical_analysis(symbol: str, days: int = 365) -> str:
    """è·å–è‚¡ç¥¨æŠ€æœ¯åˆ†ææ•°æ®"""
    try:
        # æ£€æµ‹å¸‚åœºç±»å‹å¹¶æ ‡å‡†åŒ–ä»£ç 
        market_type = _stock_manager._detect_market_type(symbol)
        normalized_symbol = _stock_manager._normalize_symbol(symbol, market_type)
        
        # è·å–å¼€å§‹æ—¶é—´æˆ³ï¼ˆ120å¤©å‰ï¼‰
        import time as time_module
        current_timestamp = int(time_module.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
        
        # æ„é€ API URL
        url = "https://stock.xueqiu.com/v5/stock/chart/kline.json"
        
        params = {
            'symbol': normalized_symbol,
            'begin': str(current_timestamp),
            'period': 'day',
            'type': 'before',
            'count': f'-{days}',
            'indicator': 'kline,pe,pb,ps,pcf,market_capital,agt,ggt,balance'
        }
        
        # è®¾ç½®è¯·æ±‚å¤´ï¼ˆæ ¹æ®æ‚¨çš„curlæµ‹è¯•ï¼‰
        headers = {
            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'accept-language': 'zh-CN,zh;q=0.9,ko;q=0.8,en-US;q=0.7,en;q=0.6',
            'cache-control': 'no-cache',
            'pragma': 'no-cache',
            'priority': 'u=0, i',
            'sec-ch-ua': '"Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"macOS"',
            'sec-fetch-dest': 'document',
            'sec-fetch-mode': 'navigate',
            'sec-fetch-site': 'none',
            'sec-fetch-user': '?1',
            'upgrade-insecure-requests': '1',
            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
            'Cookie': 's=be12bcx3pb; cookiesu=971748192631827; device_id=afda57cfe6697001d99fa8895d7a8922; u=971748192631827; Hm_lvt_1db88642e346389874251b5a1eded6e3=1748192633,1749565221; HMACCOUNT=73EFE7072B2EF8EE; xq_a_token=b7259d09435458cc3f1a963479abb270a1a016ce; xqat=b7259d09435458cc3f1a963479abb270a1a016ce; xq_r_token=28108bfa1d92ac8a46bbb57722633746218621a3; xq_id_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ1aWQiOi0xLCJpc3MiOiJ1YyIsImV4cCI6MTc1MjU0MTk4OCwiY3RtIjoxNzQ5OTk0MzEyODE0LCJjaWQiOiJkOWQwbjRBWnVwIn0.jNWjZYg_wpiX1GgMAlx7hE9ZE8pTjQg6V5NgsM7O2vSbzM_yE4np01eywM_aKem3L0sh3bMqgbpZT8IG0L61oJ7yEV84aO6wajvfSgP8NOtkNJxDk6ljYG57-fgau9Ig1Vpi49_Md-fM4BXQeza0sgHXnBLnvv7LyVks5Z1puo4mr_pGIyKYr_o5MtWRFGNZBRpDtTQ0SgYn8pQWJ9ceu9EojXvYeelq4hny4Gocgj6yvnaInlyimJA3own6mb5d0a067ypFnZ9YP3UG_jcBndeXn5OX1wNmeBcHgGTwH_vN33bo6vjb1Nqhu7v2Hb4WpLrjyK8POAFUjivQ7THdkA; Hm_lpvt_1db88642e346389874251b5a1eded6e3=1749994377; ssxmod_itna=YqUxnDcDBC0QiQ=i7NitYiOqDQK4ijKQDXDUqMq7tDRDFqApxDH8mrF5stfB=8YKnDG=45aY5D/zG7eDZDG9dDqx0ErXQA7Tthe9G7gqpPfl0Y4hkW80GSYaYQI=RxYifUzSc65c7eGImDG2DYoDCqDS0DD9R2GrDYYfDBYD74G+DDeDixbDGuuP2DDFRWbdclNQiW+PueDE000a0DDgjPD1QPWrulNqla4D0LWDfR0WleqxxY=DQwOQFoTDjR9W7KGyQeGWi8RjuKGuSZixphuNqPqU=RDSzCLxW7eM+BxPfA6hznGxngxNAD4EsPYs3AxYA4qY5=nQkxDic5Kb2rBqK4U2atq1UriXYAm=e52YI6DKrUxr/Dgpw1nwKAG5mDIA03iiGGDK3X3YD; ssxmod_itna2=YqUxnDcDBC0QiQ=i7NitYiOqDQK4ijKQDXDUqMq7tDRDFqApxDH8mrF5stfB=8YKnDG=45a7eDAQf7G+C=fQD03qe8G3TPDBMpP4WMYZ5y53fY=RcKkBFEhWq3m+7DHhYA+sYgERHupq29iQ4YMLxWw6Hebfu80DRAbQh+CiujLr2fkrnKe4DpCXx5W5eWj3lSf+Xzeh4wO0HQG2K8Gj5m8rZ7MhW=TQkrYc5K0rk57fPvfhSzTF8yQcKnL4Qwg6EgbUU7Zxipai6Kpi2uZxNLUdu2UiCM8g4T/C=cR18=7m5covxo0sEYGiCmxnrZ0pV/bDNuqzir9GE+bZKGEQRY9GPLAtQDNfGNW0qbD40BPsiKPD'
        }
        
        # ä½¿ç”¨web_scraperå‘é€APIè¯·æ±‚
        if _web_scraper is None:
            return f"[é”™è¯¯] WebæŠ“å–å·¥å…·å®ä¾‹ä¸å¯ç”¨"
        
        result = _web_scraper.api_request(
            url=url,
            method="GET",
            headers=headers,
            data=params,
            timeout=30
        )
        
        if not result['success']:
            return f"[é”™è¯¯] APIè¯·æ±‚å¤±è´¥: {result['error']}"
        
        if not result['is_json']:
            return f"[é”™è¯¯] å“åº”ä¸æ˜¯JSONæ ¼å¼"
        
        data = result['json']
        
        if data.get('error_code') != 0:
            return f"[é”™è¯¯] APIè¿”å›é”™è¯¯: {data.get('error_description', 'æœªçŸ¥é”™è¯¯')}"
        
        # è§£æKçº¿æ•°æ®
        chart_data = data.get('data', {})
        symbol_name = chart_data.get('symbol', symbol)
        columns = chart_data.get('column', [])
        items = chart_data.get('item', [])
        
        if not items:
            return f"[é”™è¯¯] æœªè·å–åˆ°{symbol}çš„Kçº¿æ•°æ®\næ•°æ®ç»“æ„: {list(data.keys())}\nchart_data: {chart_data}"
        
        # è§£ææ•°æ®åˆ—
        timestamp_idx = columns.index('timestamp')
        volume_idx = columns.index('volume')
        open_idx = columns.index('open')
        high_idx = columns.index('high')
        low_idx = columns.index('low')
        close_idx = columns.index('close')
        
        # æå–ä»·æ ¼æ•°æ®
        prices = []
        for item in items:
            if len(item) > max(timestamp_idx, volume_idx, open_idx, high_idx, low_idx, close_idx):
                prices.append({
                    'timestamp': item[timestamp_idx],
                    'open': item[open_idx],
                    'high': item[high_idx], 
                    'low': item[low_idx],
                    'close': item[close_idx],
                    'volume': item[volume_idx]
                })
        
        if len(prices) < 26:  # MACDéœ€è¦è‡³å°‘26ä¸ªæ•°æ®ç‚¹
            return f"[é”™è¯¯] æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆéœ€è¦è‡³å°‘26ä¸ªæ•°æ®ç‚¹ï¼Œå½“å‰{len(prices)}ä¸ªï¼‰"
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        analysis = _calculate_technical_indicators(prices, symbol_name)
        
        return analysis
        
    except Exception as e:
        return f"[é”™è¯¯] è·å–æŠ€æœ¯åˆ†æå¤±è´¥: {str(e)}"


def _calculate_technical_indicators(prices: list, symbol_name: str) -> str:
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¹¶è¿”å›åˆ†ææ‘˜è¦"""
    try:
        # æœ€æ–°æ•°æ®
        latest = prices[-1]
        previous = prices[-2] if len(prices) > 1 else latest
        
        # åŸºæœ¬ä»·æ ¼ä¿¡æ¯
        current_price = latest['close']
        prev_close = previous['close']
        change = current_price - prev_close
        change_pct = (change / prev_close * 100) if prev_close != 0 else 0
        
        # æœ€é«˜æœ€ä½ä»·åˆ†æ
        recent_7_days = prices[-7:] if len(prices) >= 7 else prices
        recent_30_days = prices[-30:] if len(prices) >= 30 else prices
        
        high_7d = max([p['high'] for p in recent_7_days])
        low_7d = min([p['low'] for p in recent_7_days])
        high_30d = max([p['high'] for p in recent_30_days])
        low_30d = min([p['low'] for p in recent_30_days])
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        ma5 = _calculate_ma([p['close'] for p in prices], 5)
        ma10 = _calculate_ma([p['close'] for p in prices], 10)
        ma20 = _calculate_ma([p['close'] for p in prices], 20)
        ma60 = _calculate_ma([p['close'] for p in prices], 60)
        
        # è®¡ç®—SMAï¼ˆç®€å•ç§»åŠ¨å¹³å‡çº¿ï¼‰
        sma5 = _calculate_sma([p['close'] for p in prices], 5)
        sma20 = _calculate_sma([p['close'] for p in prices], 20)
        
        # è®¡ç®—MACD
        macd_data = _calculate_macd([p['close'] for p in prices])
        
        # è®¡ç®—KDJ
        kdj_data = _calculate_kdj(prices)
        
        # è®¡ç®—BOLL
        boll_data = _calculate_boll([p['close'] for p in prices])
        
        # è®¡ç®—SAR
        sar_data = _calculate_sar(prices)
        
        # æ„å»ºæŠ€æœ¯åˆ†ææŠ¥å‘Š
        analysis = f"ğŸ“ˆ {symbol_name} æŠ€æœ¯åˆ†ææŠ¥å‘Š\n"
        analysis += "=" * 60 + "\n\n"
        
        # è‚¡ä»·ä¿¡æ¯
        analysis += f"ğŸ“Š è‚¡ä»·ä¿¡æ¯\n"
        analysis += f"å½“å‰è‚¡ä»·: {current_price:.2f}\n"
        analysis += f"æ¶¨è·Œå¹…: {change:+.2f} ({change_pct:+.2f}%)\n"
        analysis += f"æ˜¨æ”¶: {prev_close:.2f}\n"
        analysis += f"æ˜¨å¼€: {previous['open']:.2f}\n"
        analysis += f"æœ€é«˜: {latest['high']:.2f}\n"
        analysis += f"æœ€ä½: {latest['low']:.2f}\n\n"
        
        # é˜¶æ®µæœ€å€¼
        analysis += "ğŸ“ˆ é˜¶æ®µæœ€å€¼\n"
        analysis += f"è¿‘7å¤©æœ€é«˜: {high_7d:.2f}\n"
        analysis += f"è¿‘7å¤©æœ€ä½: {low_7d:.2f}\n"
        analysis += f"è¿‘30å¤©æœ€é«˜: {high_30d:.2f}\n"
        analysis += f"è¿‘30å¤©æœ€ä½: {low_30d:.2f}\n\n"
        
        # ç§»åŠ¨å¹³å‡çº¿
        analysis += "ğŸ“ˆ å‡çº¿ç³»ç»Ÿ\n"
        if ma5 and ma10 and ma20 and ma60:
            ma5_latest = ma5[-1] if ma5 else 0
            ma10_latest = ma10[-1] if ma10 else 0
            ma20_latest = ma20[-1] if ma20 else 0
            ma60_latest = ma60[-1] if ma60 else 0
            analysis += f"MA5: {ma5_latest:.2f}\n"
            analysis += f"MA10: {ma10_latest:.2f}\n"
            analysis += f"MA20: {ma20_latest:.2f}\n"
            analysis += f"MA60: {ma60_latest:.2f}\n"
            
            # å‡çº¿æ’åˆ—åˆ¤æ–­
            if ma5_latest > ma10_latest > ma20_latest > ma60_latest:
                analysis += "å‡çº¿æ’åˆ—: å®Œç¾å¤šå¤´æ’åˆ— ğŸ”´ğŸ”´\n"
            elif ma5_latest > ma20_latest:
                analysis += "å‡çº¿æ’åˆ—: å¤šå¤´æ’åˆ— ğŸ”´\n"
            else:
                analysis += "å‡çº¿æ’åˆ—: ç©ºå¤´æ’åˆ— ğŸ”µ\n"
        
        # SMAåˆ†æ
        analysis += "\nğŸ“ˆ SMAç®€å•ç§»åŠ¨å¹³å‡\n"
        if sma5 and sma20:
            sma5_latest = sma5[-1] if sma5 else 0
            sma20_latest = sma20[-1] if sma20 else 0
            analysis += f"SMA5: {sma5_latest:.2f}\n"
            analysis += f"SMA20: {sma20_latest:.2f}\n"
            
            if sma5_latest > sma20_latest:
                analysis += "SMAè¶‹åŠ¿: ä¸Šå‡è¶‹åŠ¿ ğŸ“ˆ\n"
            else:
                analysis += "SMAè¶‹åŠ¿: ä¸‹é™è¶‹åŠ¿ ğŸ“‰\n"
        analysis += "\n"
        
        # MACDåˆ†æ
        analysis += "ğŸ“ˆ MACDåˆ†æ\n"
        if macd_data:
            recent_macd = macd_data[-7:] if len(macd_data) >= 7 else macd_data
            analysis += f"è¿‘7å¤©MACDå€¼: {[f'{x:.3f}' for x in [m['macd'] for m in recent_macd]]}\n"
            
            # é‡‘å‰é“¶å‰åˆ¤æ–­
            if len(macd_data) >= 2:
                current_macd = macd_data[-1]
                previous_macd = macd_data[-2]
                
                if (current_macd['dif'] > current_macd['dea'] and 
                    previous_macd['dif'] <= previous_macd['dea']):
                    analysis += "MACDçŠ¶æ€: é‡‘å‰ ğŸŸ¡\n"
                elif (current_macd['dif'] < current_macd['dea'] and 
                      previous_macd['dif'] >= previous_macd['dea']):
                    analysis += "MACDçŠ¶æ€: æ­»å‰ âš«\n"
                else:
                    if current_macd['dif'] > current_macd['dea']:
                        analysis += "MACDçŠ¶æ€: å¤šå¤´è¶‹åŠ¿\n"
                    else:
                        analysis += "MACDçŠ¶æ€: ç©ºå¤´è¶‹åŠ¿\n"
        analysis += "\n"
        
        # KDJåˆ†æ
        analysis += "ğŸ“ˆ KDJåˆ†æ\n"
        if kdj_data:
            recent_kdj = kdj_data[-7:] if len(kdj_data) >= 7 else kdj_data
            analysis += f"è¿‘7å¤©Kå€¼: {[f'{x:.1f}' for x in [k['k'] for k in recent_kdj]]}\n"
            analysis += f"è¿‘7å¤©Då€¼: {[f'{x:.1f}' for x in [k['d'] for k in recent_kdj]]}\n"
            analysis += f"è¿‘7å¤©Jå€¼: {[f'{x:.1f}' for x in [k['j'] for k in recent_kdj]]}\n"
            
            # é‡‘å‰é“¶å‰åˆ¤æ–­
            if len(kdj_data) >= 2:
                current_kdj = kdj_data[-1]
                previous_kdj = kdj_data[-2]
                
                if (current_kdj['k'] > current_kdj['d'] and 
                    previous_kdj['k'] <= previous_kdj['d']):
                    analysis += "KDJçŠ¶æ€: é‡‘å‰ ğŸŸ¡\n"
                elif (current_kdj['k'] < current_kdj['d'] and 
                      previous_kdj['k'] >= previous_kdj['d']):
                    analysis += "KDJçŠ¶æ€: æ­»å‰ âš«\n"
                else:
                    if current_kdj['k'] > current_kdj['d']:
                        analysis += "KDJçŠ¶æ€: å¤šå¤´è¶‹åŠ¿\n"
                    else:
                        analysis += "KDJçŠ¶æ€: ç©ºå¤´è¶‹åŠ¿\n"
                
                # è¶…ä¹°è¶…å–åˆ¤æ–­
                if current_kdj['k'] > 80:
                    analysis += "KDJæç¤º: è¶…ä¹°åŒºåŸŸï¼Œæ³¨æ„å›è°ƒé£é™©\n"
                elif current_kdj['k'] < 20:
                    analysis += "KDJæç¤º: è¶…å–åŒºåŸŸï¼Œå¯èƒ½åå¼¹\n"
        analysis += "\n"
        
        # BOLLåˆ†æ
        analysis += "ğŸ“ˆ å¸ƒæ—å¸¦åˆ†æ\n"
        if boll_data:
            latest_boll = boll_data[-1]
            analysis += f"ä¸Šè½¨: {latest_boll['upper']:.2f}\n"
            analysis += f"ä¸­è½¨: {latest_boll['middle']:.2f}\n"
            analysis += f"ä¸‹è½¨: {latest_boll['lower']:.2f}\n"
            
            # ä½ç½®åˆ†æ
            if current_price > latest_boll['upper']:
                analysis += "å¸ƒæ—å¸¦ä½ç½®: ä¸Šè½¨ä¹‹ä¸Šï¼Œå¯èƒ½å›è°ƒ\n"
            elif current_price < latest_boll['lower']:
                analysis += "å¸ƒæ—å¸¦ä½ç½®: ä¸‹è½¨ä¹‹ä¸‹ï¼Œå¯èƒ½åå¼¹\n"
            elif current_price > latest_boll['middle']:
                analysis += "å¸ƒæ—å¸¦ä½ç½®: ä¸­è½¨ä¹‹ä¸Šï¼Œåå¼ºåŠ¿\n"
            else:
                analysis += "å¸ƒæ—å¸¦ä½ç½®: ä¸­è½¨ä¹‹ä¸‹ï¼Œåå¼±åŠ¿\n"
        analysis += "\n"
        
        # SARåˆ†æ
        analysis += "ğŸ“ˆ SARæŠ›ç‰©çº¿æŒ‡æ ‡\n"
        if sar_data:
            recent_sar = sar_data[-7:] if len(sar_data) >= 7 else sar_data
            latest_sar = sar_data[-1]
            analysis += f"å½“å‰SAR: {latest_sar['sar']:.2f}\n"
            sar_values = [f'{x.get("sar", 0):.2f}' for x in recent_sar]
            analysis += f"è¿‘7å¤©SAR: {sar_values}\n"
            
            # SARä¿¡å·åˆ¤æ–­
            if current_price > latest_sar['sar']:
                analysis += "SARä¿¡å·: çœ‹æ¶¨ä¿¡å· ğŸŸ¢\n"
            else:
                analysis += "SARä¿¡å·: çœ‹è·Œä¿¡å· ğŸ”´\n"
            
            # SARè½¬å‘åˆ¤æ–­
            if len(sar_data) >= 2:
                prev_sar = sar_data[-2]
                if (current_price > latest_sar['sar'] and 
                    previous['close'] <= prev_sar['sar']):
                    analysis += "SARçŠ¶æ€: åˆšåˆšè½¬ä¸ºçœ‹æ¶¨ â¬†ï¸\n"
                elif (current_price < latest_sar['sar'] and 
                      previous['close'] >= prev_sar['sar']):
                    analysis += "SARçŠ¶æ€: åˆšåˆšè½¬ä¸ºçœ‹è·Œ â¬‡ï¸\n"
        
        analysis += "\nğŸ“ æ³¨æ„ï¼šæŠ€æœ¯æŒ‡æ ‡ä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ï¼"
        
        return analysis
        
    except Exception as e:
        return f"[é”™è¯¯] è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {str(e)}"


def _calculate_ma(prices: list, period: int) -> list:
    """è®¡ç®—ç§»åŠ¨å¹³å‡çº¿"""
    if len(prices) < period:
        return []
    
    ma_values = []
    for i in range(period - 1, len(prices)):
        ma = sum(prices[i - period + 1:i + 1]) / period
        ma_values.append(ma)
    
    return ma_values


def _calculate_macd(prices: list, fast=12, slow=26, signal=9) -> list:
    """è®¡ç®—MACDæŒ‡æ ‡"""
    if len(prices) < slow:
        return []
    
    # è®¡ç®—EMA
    def calculate_ema(data, period):
        k = 2 / (period + 1)
        ema = [data[0]]
        for i in range(1, len(data)):
            ema.append(data[i] * k + ema[-1] * (1 - k))
        return ema
    
    ema_fast = calculate_ema(prices, fast)
    ema_slow = calculate_ema(prices, slow)
    
    # è®¡ç®—DIF
    dif = []
    for i in range(len(ema_slow)):
        if i < len(ema_fast):
            dif.append(ema_fast[i] - ema_slow[i])
    
    # è®¡ç®—DEA (DIFçš„EMA)
    dea = calculate_ema(dif, signal)
    
    # è®¡ç®—MACD
    macd_data = []
    for i in range(len(dea)):
        if i < len(dif):
            macd_value = (dif[i] - dea[i]) * 2
            macd_data.append({
                'dif': dif[i],
                'dea': dea[i],
                'macd': macd_value
            })
    
    return macd_data


def _calculate_kdj(prices: list, period=9) -> list:
    """è®¡ç®—KDJæŒ‡æ ‡"""
    if len(prices) < period:
        return []
    
    kdj_data = []
    k_values = []
    d_values = []
    
    for i in range(period - 1, len(prices)):
        # è·å–periodå¤©å†…çš„æœ€é«˜æœ€ä½ä»·
        period_data = prices[i - period + 1:i + 1]
        highest = max([p['high'] for p in period_data])
        lowest = min([p['low'] for p in period_data])
        
        current_close = prices[i]['close']
        
        # è®¡ç®—RSV
        if highest != lowest:
            rsv = (current_close - lowest) / (highest - lowest) * 100
        else:
            rsv = 50
        
        # è®¡ç®—Kå€¼ (3æ—¥ç§»åŠ¨å¹³å‡)
        if not k_values:
            k = rsv
        else:
            k = (2 * k_values[-1] + rsv) / 3
        
        k_values.append(k)
        
        # è®¡ç®—Då€¼ (Kå€¼çš„3æ—¥ç§»åŠ¨å¹³å‡)
        if not d_values:
            d = k
        else:
            d = (2 * d_values[-1] + k) / 3
        
        d_values.append(d)
        
        # è®¡ç®—Jå€¼
        j = 3 * k - 2 * d
        
        kdj_data.append({
            'k': k,
            'd': d, 
            'j': j
        })
    
    return kdj_data


def _calculate_boll(prices: list, period=20, std_dev=2) -> list:
    """è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡"""
    if len(prices) < period:
        return []
    
    boll_data = []
    
    for i in range(period - 1, len(prices)):
        period_prices = prices[i - period + 1:i + 1]
        
        # è®¡ç®—ä¸­è½¨ï¼ˆç§»åŠ¨å¹³å‡çº¿ï¼‰
        middle = sum(period_prices) / period
        
        # è®¡ç®—æ ‡å‡†å·®
        variance = sum([(p - middle) ** 2 for p in period_prices]) / period
        std = variance ** 0.5
        
        # è®¡ç®—ä¸Šä¸‹è½¨
        upper = middle + std_dev * std
        lower = middle - std_dev * std
        
        boll_data.append({
            'upper': upper,
            'middle': middle,
            'lower': lower
        })
    
    return boll_data


def _calculate_sma(prices: list, period: int) -> list:
    """è®¡ç®—ç®€å•ç§»åŠ¨å¹³å‡çº¿ï¼ˆSMAï¼‰"""
    if len(prices) < period:
        return []
    
    sma_values = []
    for i in range(period - 1, len(prices)):
        sma = sum(prices[i - period + 1:i + 1]) / period
        sma_values.append(sma)
    
    return sma_values


def _calculate_sar(prices: list, af_start=0.02, af_increment=0.02, af_max=0.2) -> list:
    """è®¡ç®—SARæŠ›ç‰©çº¿æŒ‡æ ‡"""
    if len(prices) < 2:
        return []
    
    sar_data = []
    
    # åˆå§‹åŒ–
    trend = 1  # 1ä¸ºä¸Šå‡è¶‹åŠ¿ï¼Œ-1ä¸ºä¸‹é™è¶‹åŠ¿
    af = af_start  # åŠ é€Ÿå› å­
    ep = prices[0]['high']  # æå€¼ç‚¹
    sar = prices[0]['low']  # SARå€¼
    
    for i in range(1, len(prices)):
        current = prices[i]
        
        # è®¡ç®—æ–°çš„SARå€¼
        new_sar = sar + af * (ep - sar)
        
        # ä¸Šå‡è¶‹åŠ¿
        if trend == 1:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬å‘
            if current['low'] <= new_sar:
                trend = -1
                sar = ep
                ep = current['low']
                af = af_start
            else:
                sar = new_sar
                # æ›´æ–°æå€¼ç‚¹
                if current['high'] > ep:
                    ep = current['high']
                    af = min(af + af_increment, af_max)
                
                # SARä¸èƒ½é«˜äºå‰ä¸¤æ—¥çš„æœ€ä½ä»·
                if i >= 2:
                    sar = min(sar, prices[i-1]['low'], prices[i-2]['low'])
        
        # ä¸‹é™è¶‹åŠ¿
        else:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬å‘
            if current['high'] >= new_sar:
                trend = 1
                sar = ep
                ep = current['high']
                af = af_start
            else:
                sar = new_sar
                # æ›´æ–°æå€¼ç‚¹
                if current['low'] < ep:
                    ep = current['low']
                    af = min(af + af_increment, af_max)
                
                # SARä¸èƒ½ä½äºå‰ä¸¤æ—¥çš„æœ€é«˜ä»·
                if i >= 2:
                    sar = max(sar, prices[i-1]['high'], prices[i-2]['high'])
        
        sar_data.append({
            'sar': sar,
            'trend': trend,
            'af': af,
            'ep': ep
        })
    
    return sar_data

@register_tool(
    name="get_stock_news",
    description="è·å–è‚¡ç¥¨ç›¸å…³çš„æœ€æ–°èµ„è®¯æ–°é—»ï¼Œæ”¯æŒæ™ºèƒ½å…³é”®è¯æœç´¢å’Œå¹¶å‘è·å–å®Œæ•´æ–°é—»å†…å®¹ã€‚å¯ä»¥è·å–æ–°é—»æ ‡é¢˜ã€å‘å¸ƒæ—¶é—´ã€æ¥æºã€æ‘˜è¦å’Œå®Œæ•´æ­£æ–‡å†…å®¹ã€‚æ”¯æŒä¸­è‹±æ–‡è‚¡ç¥¨åç§°è‡ªåŠ¨è½¬æ¢ï¼ˆå¦‚TSLAâ†’ç‰¹æ–¯æ‹‰ï¼‰ï¼Œæä¾›ä¸°å¯Œçš„å¸‚åœºèµ„è®¯ç”¨äºæŠ•èµ„å†³ç­–å‚è€ƒã€‚é»˜è®¤è·å–10ç¯‡æ–°é—»ï¼Œæ”¯æŒ1-50ç¯‡èŒƒå›´è°ƒæ•´ã€‚",
    schema={
        "type": "object",
        "properties": {
            "symbol": {
                "type": "string",
                "description": "è‚¡ç¥¨ä»£ç ï¼Œå¦‚ TSLAã€688111ã€00700"
            },
            "count": {
                "type": "integer",
                "description": "è·å–æ–°é—»æ•°é‡ï¼Œé»˜è®¤10æ¡",
                "default": 10,
                "minimum": 1,
                "maximum": 50
            },
            "include_summary": {
                "type": "boolean",
                "description": "æ˜¯å¦åŒ…å«æ–°é—»æ‘˜è¦ï¼Œé»˜è®¤True",
                "default": True
            },
            "fetch_full_content": {
                "type": "boolean",
                "description": "æ˜¯å¦å¹¶å‘è·å–å®Œæ•´æ–°é—»å†…å®¹ï¼Œé»˜è®¤False",
                "default": False
            },
            "max_content_length": {
                "type": "integer",
                "description": "æ¯ç¯‡æ–°é—»å†…å®¹æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤5000å­—ç¬¦",
                "default": 5000,
                "minimum": 200,
                "maximum": 10000
            }
        },
        "required": ["symbol"]
    }
)
def get_stock_news(symbol: str, count: int = 10, include_summary: bool = True, 
                  fetch_full_content: bool = False, max_content_length: int = 5000) -> str:
    """è·å–è‚¡ç¥¨ç›¸å…³èµ„è®¯æ–°é—»"""
    try:
        # æ£€æµ‹å¸‚åœºç±»å‹å¹¶æ ‡å‡†åŒ–ä»£ç 
        market_type = _stock_manager._detect_market_type(symbol)
        normalized_symbol = _stock_manager._normalize_symbol(symbol, market_type)
        
        # æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šæœç´¢å…³é”®è¯
        if market_type == MarketType.US:
            # ç¾è‚¡ä½¿ç”¨è‚¡ç¥¨ä»£ç 
            if symbol.upper() == 'TSLA':
                keyword = 'ç‰¹æ–¯æ‹‰'  # ä½¿ç”¨ä¸­æ–‡åç§°æœç´¢æ›´å‡†ç¡®
            else:
                keyword = symbol.upper()
        elif market_type == MarketType.HK:
            # æ¸¯è‚¡ä½¿ç”¨å…¬å¸ä¸­æ–‡åç§°
            if symbol in ['00700', '0700']:
                keyword = 'è…¾è®¯'
            else:
                keyword = symbol
        elif market_type == MarketType.CN:
            # Aè‚¡ä½¿ç”¨å…¬å¸åç§°
            if symbol in ['688111', 'SH688111']:
                keyword = 'é‡‘å±±åŠå…¬'
            else:
                keyword = symbol
        else:
            keyword = symbol
        
        # æ„é€ ä¸œæ–¹è´¢å¯Œæœç´¢API
        import json
        import urllib.parse
        import time
        import random
        
        # ç”Ÿæˆéšæœºçš„jQueryå›è°ƒå‡½æ•°åå’Œæ—¶é—´æˆ³
        callback = f"jQuery{random.randint(10000000000000000000, 99999999999999999999)}_{int(time.time() * 1000)}"
        timestamp = int(time.time() * 1000)
        
        # æ„é€ æœç´¢å‚æ•°
        search_param = {
            "uid": "",
            "keyword": keyword,
            "type": ["cmsArticleWebOld"],
            "client": "web",
            "clientType": "web", 
            "clientVersion": "curr",
            "param": {
                "cmsArticleWebOld": {
                    "searchScope": "default",
                    "sort": "default",
                    "pageIndex": 1,
                    "pageSize": min(count, 20),  # é™åˆ¶æœ€å¤§20æ¡
                    "preTag": "<em>",
                    "postTag": "</em>"
                }
            }
        }
        
        # URLç¼–ç å‚æ•°
        param_str = urllib.parse.quote(json.dumps(search_param, ensure_ascii=False))
        
        # æ„é€ å®Œæ•´URL
        api_url = f"https://search-api-web.eastmoney.com/search/jsonp?cb={callback}&param={param_str}&_={timestamp}"
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Referer': 'https://so.eastmoney.com/',
            'Accept-Encoding': 'gzip, deflate, br'
        }
        
        # ä½¿ç”¨web_scraperå‘é€è¯·æ±‚
        if _web_scraper is None:
            return f"[é”™è¯¯] WebæŠ“å–å·¥å…·å®ä¾‹ä¸å¯ç”¨"
        
        result = _web_scraper.api_request(
            url=api_url,
            method="GET",
            headers=headers,
            timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´
        )
        
        if not result['success']:
            return f"[é”™è¯¯] ä¸œæ–¹è´¢å¯ŒAPIè¯·æ±‚å¤±è´¥: {result['error']}"
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"æœç´¢å…³é”®è¯: {keyword}")
        
        # è§£æJSONPå“åº”
        news_items = _parse_eastmoney_response(result['content'], callback, count)
        
        if not news_items:
            return f"[æç¤º] æœªæ‰¾åˆ°å…³äº'{keyword}'çš„ç›¸å…³æ–°é—»"
        
        # å¦‚æœéœ€è¦è·å–å®Œæ•´å†…å®¹ï¼Œå¹¶å‘è·å–æ–°é—»é¡µé¢å†…å®¹
        if fetch_full_content:
            print(f"æ­£åœ¨å¹¶å‘è·å– {len(news_items)} ç¯‡æ–°é—»çš„å®Œæ•´å†…å®¹...")
            news_items = _fetch_news_content_concurrent(news_items, max_content_length)
        
        # æ„å»ºæ–°é—»æŠ¥å‘Š
        analysis = f"ğŸ“° {symbol} ({keyword}) è‚¡ç¥¨èµ„è®¯\n"
        analysis += "=" * 60 + "\n\n"
        
        for i, item in enumerate(news_items, 1):
            analysis += f"ğŸ“„ æ–°é—» {i}\n"
            analysis += f"æ ‡é¢˜: {item['title']}\n"
            analysis += f"å‘å¸ƒæ—¶é—´: {item['pub_date']}\n"
            analysis += f"æ¥æº: {item.get('source', 'ä¸œæ–¹è´¢å¯Œ')}\n"
            
            # æ˜¾ç¤ºå†…å®¹ï¼ˆä¼˜å…ˆæ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼Œå…¶æ¬¡æ˜¯æ‘˜è¦ï¼‰
            if fetch_full_content and item.get('full_content'):
                analysis += f"å®Œæ•´å†…å®¹: {item['full_content']}\n"
            elif include_summary and item.get('content'):
                # æ¸…ç†HTMLæ ‡ç­¾
                content = _clean_html_tags(item['content'])
                if content:
                    analysis += f"æ‘˜è¦: {content[:200]}{'...' if len(content) > 200 else ''}\n"
            
            if item.get('url'):
                analysis += f"é“¾æ¥: {item['url']}\n"
            
            analysis += "\n" + "-" * 50 + "\n\n"
        
        analysis += f"ğŸ“Š å…±è·å–åˆ° {len(news_items)} æ¡ç›¸å…³æ–°é—»\n"
        if fetch_full_content:
            analysis += "ğŸ“– å·²è·å–å®Œæ•´æ–°é—»å†…å®¹\n"
        analysis += "ğŸ“ æ³¨æ„ï¼šæ–°é—»å†…å®¹ä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„å†³ç­–è¯·è°¨æ…ï¼"
        
        return analysis
        
    except Exception as e:
        return f"[é”™è¯¯] è·å–è‚¡ç¥¨èµ„è®¯å¤±è´¥: {str(e)}"


def _parse_eastmoney_response(response: str, callback: str, max_count: int) -> list:
    """è§£æä¸œæ–¹è´¢å¯ŒAPIå“åº”"""
    try:
        import json
        import re
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…JSONPæ ¼å¼: jQueryå›è°ƒå‡½æ•°å(JSONæ•°æ®);
        jsonp_pattern = r'jQuery\d+_\d+\((.*)\);?$'
        match = re.search(jsonp_pattern, response, re.DOTALL)
        
        if match:
            json_str = match.group(1)
        else:
            # å¦‚æœæ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æŸ¥æ‰¾
            start_idx = response.find('(')
            end_idx = response.rfind(');')
            
            if start_idx != -1 and end_idx != -1:
                json_str = response[start_idx + 1:end_idx]
            else:
                return []
        
        # è§£æJSON
        data = json.loads(json_str)
        
        # æ£€æŸ¥APIè¿”å›çŠ¶æ€
        if data.get('code') != 0:
            return []
        
        # æå–æ–°é—»åˆ—è¡¨
        result_data = data.get('result', {})
        news_list = result_data.get('cmsArticleWebOld', [])
        
        if not news_list:
            return []
        
        # åªæå–éœ€è¦çš„å­—æ®µ
        news_items = []
        for news in news_list:
            title = news.get('title', '')
            pub_date = news.get('date', '')
            source = news.get('mediaName', 'ä¸œæ–¹è´¢å¯Œ')
            url = news.get('url', '')
            content = news.get('content', '')
            
            if title:
                news_items.append({
                    'title': title,
                    'pub_date': pub_date,
                    'source': source,
                    'url': url,
                    'content': content
                })
            
            if len(news_items) >= max_count:
                break
        
        return news_items
        
    except Exception as e:
        print(f"è§£æä¸œæ–¹è´¢å¯ŒAPIå“åº”å¤±è´¥: {str(e)}")
        return []


def _clean_html_tags(text: str) -> str:
    """æ¸…ç†HTMLæ ‡ç­¾"""
    try:
        import re
        if not text:
            return ""
        
        # ç§»é™¤HTMLæ ‡ç­¾
        clean_text = re.sub(r'<[^>]+>', '', text)
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        # è§£ç HTMLå®ä½“
        clean_text = clean_text.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>').replace('&quot;', '"').replace('&#39;', "'")
        
        return clean_text
        
    except Exception:
        return text or ""


def _fetch_news_content_concurrent(news_items: list, max_content_length: int = 5000) -> list:
    """å¹¶å‘è·å–æ–°é—»é¡µé¢çš„å®Œæ•´å†…å®¹"""
    try:
        import concurrent.futures
        from urllib.parse import urlparse
        
        def fetch_single_news_content(index_and_news):
            """è·å–å•ä¸ªæ–°é—»çš„å®Œæ•´å†…å®¹ï¼Œä¿æŒç´¢å¼•"""
            index, news_item = index_and_news
            try:
                url = news_item.get('url', '')
                if not url:
                    return index, news_item
                
                # æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ
                parsed_url = urlparse(url)
                if not parsed_url.scheme or not parsed_url.netloc:
                    return index, news_item
                
                # ä½¿ç”¨web_scraperè·å–é¡µé¢å†…å®¹
                if _web_scraper is None:
                    return index, news_item
                
                result = _web_scraper.fetch_page(url, timeout=10)
                
                if not result['success']:
                    print(f"è·å–æ–°é—»å†…å®¹å¤±è´¥: {url} - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    return index, news_item
                
                # æå–ä¸»è¦å†…å®¹
                full_content = _web_scraper.extract_main_content(result['content'], url)
                
                if full_content:
                    # æ¸…ç†å’Œæˆªæ–­å†…å®¹
                    clean_content = _clean_html_tags(full_content)
                    if len(clean_content) > max_content_length:
                        clean_content = clean_content[:max_content_length] + "..."
                    
                    # åˆ›å»ºæ–°çš„æ–°é—»é¡¹ï¼ŒåŒ…å«å®Œæ•´å†…å®¹
                    updated_news_item = news_item.copy()
                    updated_news_item['full_content'] = clean_content
                    print(f"âœ“ æˆåŠŸè·å–æ–°é—»å†…å®¹: {news_item.get('title', 'Unknown')[:50]}...")
                    return index, updated_news_item
                else:
                    print(f"âœ— æ— æ³•æå–æ–°é—»å†…å®¹: {url}")
                    return index, news_item
                
            except Exception as e:
                print(f"è·å–æ–°é—»å†…å®¹å¼‚å¸¸: {news_item.get('url', 'Unknown')} - {str(e)}")
                return index, news_item
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–æ–°é—»å†…å®¹
        max_workers = min(5, len(news_items))  # æœ€å¤š5ä¸ªå¹¶å‘çº¿ç¨‹
        results = [None] * len(news_items)  # é¢„åˆ†é…ç»“æœæ•°ç»„
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ŒåŒ…å«ç´¢å¼•ä¿¡æ¯
            futures = [
                executor.submit(fetch_single_news_content, (i, news_item))
                for i, news_item in enumerate(news_items)
            ]
            
            # æ”¶é›†ç»“æœå¹¶æŒ‰åŸå§‹é¡ºåºæ’åˆ—
            for future in concurrent.futures.as_completed(futures, timeout=60):
                try:
                    index, updated_news_item = future.result()
                    results[index] = updated_news_item
                except Exception as e:
                    print(f"å¤„ç†æ–°é—»å¤±è´¥: {str(e)}")
                    # å¦‚æœå¤±è´¥ï¼Œä¿æŒåŸå§‹æ–°é—»é¡¹
                    for i, news_item in enumerate(news_items):
                        if results[i] is None:
                            results[i] = news_item
                            break
        
        # ç¡®ä¿æ‰€æœ‰ä½ç½®éƒ½æœ‰å€¼ï¼ˆé˜²æ­¢Noneï¼‰
        final_results = []
        for i, result in enumerate(results):
            if result is not None:
                final_results.append(result)
            else:
                final_results.append(news_items[i])
        
        success_count = sum(1 for item in final_results if item.get('full_content'))
        print(f"å¹¶å‘è·å–å®Œæˆï¼ŒæˆåŠŸè·å– {success_count} ç¯‡å®Œæ•´å†…å®¹")
        return final_results
        
    except Exception as e:
        print(f"å¹¶å‘è·å–æ–°é—»å†…å®¹å¤±è´¥: {str(e)}")
        return news_items


# ==================== è‚¡ç¥¨æ’è¡Œæ¦œåŠŸèƒ½ ====================

@register_tool(
    name="get_stock_ranking",
    description="è·å–å®æ—¶è‚¡ç¥¨å¸‚åœºæ’è¡Œæ¦œæ•°æ®ï¼Œæ”¯æŒå¤šç§æ’è¡Œæ¦œç±»å‹å’Œä¸‰å¤§ä¸»è¦å¸‚åœºã€‚åŒ…æ‹¬æ¶¨å¹…æ¦œï¼ˆå½“æ—¥æ¶¨å¹…æœ€å¤§çš„è‚¡ç¥¨ï¼‰ã€è·Œå¹…æ¦œï¼ˆå½“æ—¥è·Œå¹…æœ€å¤§çš„è‚¡ç¥¨ï¼‰ã€æˆäº¤é‡æ¦œï¼ˆå½“æ—¥æˆäº¤é‡æœ€å¤§çš„è‚¡ç¥¨ï¼‰ã€æˆäº¤é¢æ¦œï¼ˆå½“æ—¥æˆäº¤é‡‘é¢æœ€å¤§çš„è‚¡ç¥¨ï¼‰ã€‚è¦†ç›–ç¾è‚¡ã€æ¸¯è‚¡ã€Aè‚¡ä¸‰å¤§å¸‚åœºï¼Œæä¾›è‚¡ç¥¨ä»£ç ã€åç§°ã€å½“å‰ä»·æ ¼ã€æ¶¨è·Œå¹…ã€æ¶¨è·Œé¢ã€æˆäº¤é‡ã€æˆäº¤é¢ç­‰è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºå¸‚åœºçƒ­ç‚¹åˆ†æå’ŒæŠ•èµ„æœºä¼šå‘ç°ã€‚",
    schema={
        "type": "object",
        "properties": {
            "market": {
                "type": "string",
                "description": "ç›®æ ‡å¸‚åœºç±»å‹ï¼šUS=ç¾è‚¡å¸‚åœºï¼ˆçº³æ–¯è¾¾å…‹ã€çº½äº¤æ‰€ç­‰ï¼‰ï¼ŒHK=æ¸¯è‚¡å¸‚åœºï¼ˆé¦™æ¸¯äº¤æ˜“æ‰€ï¼‰ï¼ŒCN=Aè‚¡å¸‚åœºï¼ˆä¸Šäº¤æ‰€ã€æ·±äº¤æ‰€ã€åŒ—äº¤æ‰€ï¼‰",
                "enum": ["US", "HK", "CN"],
                "default": "CN"
            },
            "ranking_type": {
                "type": "string", 
                "description": "æ’è¡Œæ¦œç±»å‹ï¼šrise=æ¶¨å¹…æ¦œï¼ˆæŒ‰æ¶¨è·Œå¹…é™åºï¼‰ï¼Œfall=è·Œå¹…æ¦œï¼ˆæŒ‰æ¶¨è·Œå¹…å‡åºï¼‰ï¼Œvolume=æˆäº¤é‡æ¦œï¼ˆæŒ‰æˆäº¤é‡é™åºï¼‰ï¼Œturnover=æˆäº¤é¢æ¦œï¼ˆæŒ‰æˆäº¤é‡‘é¢é™åºï¼‰",
                "enum": ["rise", "fall", "volume", "turnover"],
                "default": "rise"
            },
            "count": {
                "type": "integer",
                "description": "è¿”å›çš„è‚¡ç¥¨æ•°é‡ï¼ŒèŒƒå›´1-50åªï¼Œé»˜è®¤20åªã€‚æ•°é‡è¶Šå¤šæŸ¥è¯¢æ—¶é—´è¶Šé•¿",
                "default": 20,
                "minimum": 1,
                "maximum": 50
            }
        },
        "required": ["market"]
    }
)
def get_stock_ranking(market: str = "CN", ranking_type: str = "rise", count: int = 20) -> str:
    """è·å–è‚¡ç¥¨æ’è¡Œæ¦œ"""
    try:
        import json
        import urllib.parse
        import time
        import random
        
        # ç”Ÿæˆéšæœºçš„jQueryå›è°ƒå‡½æ•°åå’Œæ—¶é—´æˆ³
        callback = f"jQuery{random.randint(10000000000000000000, 99999999999999999999)}_{int(time.time() * 1000)}"
        timestamp = int(time.time() * 1000)
        
        # æ ¹æ®å¸‚åœºç±»å‹è®¾ç½®å‚æ•°
        if market == "US":
            # ç¾è‚¡å¸‚åœº
            fs_param = "m:105,m:106,m:107"
            fields = "f12,f13,f14,f1,f2,f4,f3,f152,f17,f28,f15,f16,f18,f20,f115"
            market_name = "ç¾è‚¡"
        elif market == "HK":
            # æ¸¯è‚¡å¸‚åœº
            fs_param = "m:128+t:3"
            fields = "f12,f13,f14,f19,f1,f2,f4,f3,f152,f17,f18,f15,f16,f5,f6"
            market_name = "æ¸¯è‚¡"
        elif market == "CN":
            # Aè‚¡å¸‚åœº
            fs_param = "m:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23,m:0+t:81+s:2048"
            fields = "f12,f13,f14,f1,f2,f4,f3,f152,f5,f6,f7,f15,f18,f16,f17,f10,f8,f9,f23"
            market_name = "Aè‚¡"
        else:
            return f"[é”™è¯¯] ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market}"
        
        # æ ¹æ®æ’è¡Œæ¦œç±»å‹è®¾ç½®æ’åºå­—æ®µ
        if ranking_type == "rise":
            fid = "f3"  # æŒ‰æ¶¨è·Œå¹…æ’åº
            po = "1"    # é™åº
            ranking_name = "æ¶¨å¹…æ¦œ"
        elif ranking_type == "fall":
            fid = "f3"  # æŒ‰æ¶¨è·Œå¹…æ’åº
            po = "0"    # å‡åº
            ranking_name = "è·Œå¹…æ¦œ"
        elif ranking_type == "volume":
            fid = "f5"  # æŒ‰æˆäº¤é‡æ’åº
            po = "1"    # é™åº
            ranking_name = "æˆäº¤é‡æ¦œ"
        elif ranking_type == "turnover":
            fid = "f6"  # æŒ‰æˆäº¤é¢æ’åº
            po = "1"    # é™åº
            ranking_name = "æˆäº¤é¢æ¦œ"
        else:
            return f"[é”™è¯¯] ä¸æ”¯æŒçš„æ’è¡Œæ¦œç±»å‹: {ranking_type}ï¼Œä»…æ”¯æŒriseã€fallã€volumeã€turnover"
        
        # æ„é€ API URL
        base_url = "https://push2.eastmoney.com/api/qt/clist/get"
        params = {
            "np": "1",
            "fltt": "1", 
            "invt": "2",
            "cb": callback,
            "fs": fs_param,
            "fields": fields,
            "fid": fid,
            "pn": "1",
            "pz": str(min(count, 50)),
            "po": po,
            "dect": "1",
            "ut": "fa5fd1943c7b386f172d6893dbfba10b",
            "wbp2u": "|0|0|0|web",
            "_": str(timestamp)
        }
        
        # æ„é€ å®Œæ•´URL
        api_url = f"{base_url}?" + "&".join([f"{k}={urllib.parse.quote(str(v))}" for k, v in params.items()])
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Referer': 'https://quote.eastmoney.com/center/gridlist.html',
            'Accept-Encoding': 'gzip, deflate, br'
        }
        
        # ä½¿ç”¨web_scraperå‘é€è¯·æ±‚
        if _web_scraper is None:
            return f"[é”™è¯¯] WebæŠ“å–å·¥å…·å®ä¾‹ä¸å¯ç”¨"
        
        result = _web_scraper.api_request(
            url=api_url,
            method="GET",
            headers=headers,
            timeout=60
        )
        
        if not result['success']:
            return f"[é”™è¯¯] ä¸œæ–¹è´¢å¯Œæ’è¡Œæ¦œAPIè¯·æ±‚å¤±è´¥: {result['error']}"
        
        # è§£æJSONPå“åº”
        ranking_data = _parse_ranking_response(result['content'], callback, count)
        
        if not ranking_data:
            return f"[æç¤º] æœªè·å–åˆ°{market_name}{ranking_name}æ•°æ®"
        
        # æ„å»ºæ’è¡Œæ¦œæŠ¥å‘Š
        analysis = f"ğŸ“Š {market_name}{ranking_name}\n"
        analysis += "=" * 60 + "\n\n"
        
        for i, stock in enumerate(ranking_data, 1):
            analysis += f"ğŸ† ç¬¬{i}å\n"
            analysis += f"è‚¡ç¥¨ä»£ç : {stock['code']}\n"
            analysis += f"è‚¡ç¥¨åç§°: {stock['name']}\n"
            analysis += f"å½“å‰ä»·æ ¼: {stock['price']}\n"
            analysis += f"æ¶¨è·Œå¹…: {stock['change_percent']}\n"
            analysis += f"æ¶¨è·Œé¢: {stock['change_amount']}\n"
            
            if market == "CN":
                analysis += f"æˆäº¤é‡: {stock.get('volume', 'N/A')}\n"
                analysis += f"æˆäº¤é¢: {stock.get('turnover', 'N/A')}\n"
            elif market == "US":
                analysis += f"æˆäº¤é‡: {stock.get('volume', 'N/A')}\n"
            
            analysis += "\n" + "-" * 50 + "\n\n"
        
        analysis += f"ğŸ“ˆ å…±è·å–åˆ° {len(ranking_data)} åªè‚¡ç¥¨\n"
        analysis += "ğŸ“ æ³¨æ„ï¼šæ’è¡Œæ¦œæ•°æ®ä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„å†³ç­–è¯·è°¨æ…ï¼"
        
        return analysis
        
    except Exception as e:
        return f"[é”™è¯¯] è·å–è‚¡ç¥¨æ’è¡Œæ¦œå¤±è´¥: {str(e)}"


def _parse_ranking_response(response: str, callback: str, max_count: int) -> list:
    """è§£æä¸œæ–¹è´¢å¯Œæ’è¡Œæ¦œAPIå“åº”"""
    try:
        import json
        import re
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…JSONPæ ¼å¼
        jsonp_pattern = r'jQuery\d+_\d+\((.*)\);?$'
        match = re.search(jsonp_pattern, response, re.DOTALL)
        
        if match:
            json_str = match.group(1)
        else:
            # å¦‚æœæ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æŸ¥æ‰¾
            start_idx = response.find('(')
            end_idx = response.rfind(');')
            
            if start_idx != -1 and end_idx != -1:
                json_str = response[start_idx + 1:end_idx]
            else:
                return []
        
        # è§£æJSON
        data = json.loads(json_str)
        
        # æ£€æŸ¥APIè¿”å›çŠ¶æ€
        if data.get('rc') != 0:
            return []
        
        # æå–è‚¡ç¥¨åˆ—è¡¨
        stock_list = data.get('data', {}).get('diff', [])
        
        if not stock_list:
            return []
        
        # è§£æè‚¡ç¥¨æ•°æ®
        ranking_items = []
        for stock in stock_list:
            code = stock.get('f12', '')
            name = stock.get('f14', '')
            price = stock.get('f2', 0)
            change_percent = stock.get('f3', 0)
            change_amount = stock.get('f4', 0)
            volume = stock.get('f5', 0)
            turnover = stock.get('f6', 0)
            
            if code and name:
                # æ ¼å¼åŒ–æ•°æ®
                price_str = f"{price/100:.2f}" if price else "N/A"
                change_percent_str = f"{change_percent/100:+.2f}%" if change_percent else "N/A"
                change_amount_str = f"{change_amount/100:+.2f}" if change_amount else "N/A"
                
                # æ ¼å¼åŒ–æˆäº¤é‡å’Œæˆäº¤é¢
                volume_str = _format_volume(volume) if volume else "N/A"
                turnover_str = _format_turnover(turnover) if turnover else "N/A"
                
                ranking_items.append({
                    'code': code,
                    'name': name,
                    'price': price_str,
                    'change_percent': change_percent_str,
                    'change_amount': change_amount_str,
                    'volume': volume_str,
                    'turnover': turnover_str
                })
            
            if len(ranking_items) >= max_count:
                break
        
        return ranking_items
        
    except Exception as e:
        print(f"è§£æä¸œæ–¹è´¢å¯Œæ’è¡Œæ¦œAPIå“åº”å¤±è´¥: {str(e)}")
        return []


def _format_volume(volume):
    """æ ¼å¼åŒ–æˆäº¤é‡"""
    if volume >= 100000000:  # äº¿
        return f"{volume/100000000:.2f}äº¿æ‰‹"
    elif volume >= 10000:  # ä¸‡
        return f"{volume/10000:.2f}ä¸‡æ‰‹"
    else:
        return f"{volume}æ‰‹"


def _format_turnover(turnover):
    """æ ¼å¼åŒ–æˆäº¤é¢"""
    if turnover >= 100000000:  # äº¿
        return f"{turnover/100000000:.2f}äº¿å…ƒ"
    elif turnover >= 10000:  # ä¸‡
        return f"{turnover/10000:.2f}ä¸‡å…ƒ"
    else:
        return f"{turnover:.2f}å…ƒ"


if __name__ == "__main__":
    # æµ‹è¯•è‚¡ç¥¨ä¿¡æ¯å·¥å…·
    print("=== è‚¡ç¥¨ä¿¡æ¯å·¥å…·æµ‹è¯• ===\n")
    
    # æµ‹è¯•è‚¡ç¥¨ä»£ç 
    test_symbols = ['TSLA', '688111', '00700']
    
    for symbol in test_symbols:
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•è‚¡ç¥¨: {symbol}")
        print(f"{'='*60}")
        
        # 1. æµ‹è¯•æŠ€æœ¯åˆ†æ
        print(f"\nğŸ“ˆ è·å– {symbol} æŠ€æœ¯åˆ†æ:")
        try:
            tech_analysis = get_technical_analysis(symbol)
            print(tech_analysis)
        except Exception as e:
            print(f"æŠ€æœ¯åˆ†æè·å–å¤±è´¥: {e}")
        
        # 2. æµ‹è¯•è‚¡ç¥¨èµ„è®¯ï¼ˆä¸œæ–¹è´¢å¯ŒAPIï¼‰
        print(f"\nğŸ“° è·å– {symbol} è‚¡ç¥¨èµ„è®¯:")
        try:
            news_result = get_stock_news(symbol, count=3)
            print(news_result)
        except Exception as e:
            print(f"è‚¡ç¥¨èµ„è®¯è·å–å¤±è´¥: {e}")
        
        print(f"\n{'-'*60}")
        print("ç­‰å¾…2ç§’åç»§ç»­ä¸‹ä¸€ä¸ªè‚¡ç¥¨...")
        import time
        time.sleep(2)
    
    # æµ‹è¯•å¹¶å‘è·å–å®Œæ•´æ–°é—»å†…å®¹åŠŸèƒ½
    print(f"\n{'='*60}")
    print("æµ‹è¯•å¹¶å‘è·å–å®Œæ•´æ–°é—»å†…å®¹åŠŸèƒ½")
    print(f"{'='*60}")
    
    print(f"\nğŸ“– è·å– TSLA çš„å®Œæ•´æ–°é—»å†…å®¹ï¼ˆå¹¶å‘æ¨¡å¼ï¼‰:")
    try:
        full_news_result = get_stock_news("TSLA", count=2, fetch_full_content=True, max_content_length=500)
        print(full_news_result)
    except Exception as e:
        print(f"è·å– TSLA å®Œæ•´æ–°é—»å†…å®¹å¤±è´¥: {e}")
    
    print(f"\n{'-'*60}")
    import time
    time.sleep(2)
    
    # 3. æµ‹è¯•è‚¡ç¥¨æ’è¡Œæ¦œåŠŸèƒ½
    print(f"\n{'='*60}")
    print("æµ‹è¯•è‚¡ç¥¨æ’è¡Œæ¦œåŠŸèƒ½")
    print(f"{'='*60}")
    
    ranking_tests = [
        ("CN", "rise", "Aè‚¡æ¶¨å¹…æ¦œ"),
        ("US", "rise", "ç¾è‚¡æ¶¨å¹…æ¦œ"),
        ("HK", "rise", "æ¸¯è‚¡æ¶¨å¹…æ¦œ"),
        ("CN", "fall", "Aè‚¡è·Œå¹…æ¦œ"),
        ("CN", "volume", "Aè‚¡æˆäº¤é‡æ¦œ")
    ]
    
    for market, ranking_type, name in ranking_tests:
        print(f"\nğŸ“Š è·å– {name}:")
        try:
            ranking_result = get_stock_ranking(market, ranking_type, 3)
            print(ranking_result)
        except Exception as e:
            print(f"{name}è·å–å¤±è´¥: {e}")
        
        print(f"\n{'-'*40}")
        import time
        time.sleep(1)
    
    print(f"\n{'='*60}")
    print("æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*60}")